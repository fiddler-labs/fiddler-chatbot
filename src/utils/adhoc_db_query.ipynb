{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9086acc",
   "metadata": {},
   "source": [
    "\n",
    "# Fiddler Chatbot Database Administration Notebook\n",
    "\n",
    "This notebook provides administrative tools for managing the Fiddler chatbot database systems.\n",
    "- **Vector Store Table**: `fiddler_doc_snippets_openai`\n",
    "- **Chatbot Ledger Table**: `fiddler_chatbot_ledger` \n",
    "- **Keyspace**: `fiddlerai`\n",
    "- **Current LLM Model**: `gpt-4-turbo`\n",
    "- **Embedding Model**: `text-embedding-3-large`\n",
    "\n",
    "### 1. **Data Inspection**\n",
    "   - Views contents of vector store and ledger tables\n",
    "   - Checks table structures and row counts\n",
    "   - Analyzes data quality and completeness\n",
    "\n",
    "### 2. **Data Analysis**\n",
    "   - Examines chatbot interaction patterns\n",
    "   - Reviews user feedback and ratings\n",
    "   - Analyzes token usage and costs\n",
    "\n",
    "### 3. **Data Export**\n",
    "   - Exports data for Fiddler AI monitoring\n",
    "   - Creates CSV files for analysis\n",
    "   - Prepares baseline and event datasets\n",
    "\n",
    "### 4. **Maintenance Operations**\n",
    "   - Data cleanup and validation\n",
    "   - Performance monitoring\n",
    "   - Schema validation\n",
    "\n",
    "**‚ö†Ô∏è Important**: This notebook has been updated to align with the current system configuration as of 2025. Legacy migration code has been preserved but marked as historical reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4096ec-29eb-4cfa-8346-7b283cbd23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cassandra\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print( os.getcwd() )\n",
    "os.chdir('../')\n",
    "print( os.getcwd() )\n",
    "\n",
    "from config import CONFIG_CHATBOT_OLD as config  # noqa: E402\n",
    "\n",
    "print(f\"Cassandra version: {cassandra.__version__}\")\n",
    "print(\"Current system configuration loaded:\")\n",
    "print(f\"  - Keyspace:        {config['ASTRA_DB_KEYSPACE']}\")\n",
    "print(f\"  - Vector table:    {config['ASTRA_DB_TABLE_NAME']}\")\n",
    "print(f\"  - Ledger table:    {config['ASTRA_DB_LEDGER_TABLE_NAME']}\")\n",
    "print(f\"  - LLM Model:       {config['OPENAI_LLM_MODEL']}\")\n",
    "print(f\"  - Embedding Model: {config['OPENAI_EMBEDDING_MODEL']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b3d41-2153-45c4-b37b-8567ca48c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This secure connect bundle is autogenerated when you donwload your SCB, if yours is different update the file name below\n",
    "# Database connection setup using current configuration\n",
    "print(\"üîÑ Setting up database connection...\")\n",
    "\n",
    "cloud_config = {\n",
    "    'secure_connect_bundle': '../'+config[\"ASTRA_DB_SECURE_BUNDLE_PATH\"]\n",
    "}\n",
    "\n",
    "# Get authentication token from environment\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.environ.get('ASTRA_DB_APPLICATION_TOKEN')\n",
    "if not ASTRA_DB_APPLICATION_TOKEN:\n",
    "    raise ValueError(\"ASTRA_DB_APPLICATION_TOKEN environment variable is required\")\n",
    "\n",
    "# Create connection\n",
    "auth_provider = PlainTextAuthProvider(\"token\", ASTRA_DB_APPLICATION_TOKEN)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()\n",
    "\n",
    "# Set keyspace using configuration\n",
    "keyspace = config[\"ASTRA_DB_KEYSPACE\"]\n",
    "session.set_keyspace(keyspace)\n",
    "\n",
    "print(\"‚úÖ Connected to DataStax Astra DB using keyspace: {keyspace}\")\n",
    "\n",
    "def pandas_factory(colnames, rows):\n",
    "    return pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "session.row_factory = pandas_factory\n",
    "# session.default_fetch_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc9d69-43c3-4cf6-88a2-f243a3a8d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rid = \"<class 'uuid.UUID'>\"\n",
    "# rows = session.execute(\"DELETE row_id FROM fiddler_chatbot_ledger WHERE model_name= '' \")\n",
    "# df = rows._current_rows\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c18fb6-71ca-4195-98fb-4363a1f6c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the main vector store table\n",
    "vector_table = config[\"ASTRA_DB_TABLE_NAME\"]\n",
    "print(f\"üìä Querying vector store table: {vector_table}\")\n",
    "\n",
    "query = f'SELECT * FROM {vector_table}'\n",
    "rows = session.execute(query)\n",
    "df_docs = rows._current_rows\n",
    "\n",
    "print(f\"üìà Retrieved {len(df_docs)} documents from vector store\")\n",
    "print(f\"üìã Table schema: {list(df_docs.columns)}\")\n",
    "\n",
    "# Display basic statistics\n",
    "if len(df_docs) > 0:\n",
    "    print(f\"üìè Vector dimensions: {len(df_docs.iloc[0]['vector']) if 'vector' in df_docs.columns else 'N/A'}\")\n",
    "    print(f\"üìù Sample document preview: {str(df_docs.iloc[0]['body_blob'])[:100]}...\" if 'body_blob' in df_docs.columns else \"\")\n",
    "\n",
    "df_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdec1b8-6a78-47e4-9ef7-5678baa56de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the current chatbot interaction ledger\n",
    "ledger_table = config[\"ASTRA_DB_LEDGER_TABLE_NAME\"]\n",
    "print(f\"üìä Querying chatbot ledger table: {ledger_table}\")\n",
    "\n",
    "query = f\"SELECT * FROM {ledger_table} LIMIT 100\"\n",
    "rows = session.execute(query)\n",
    "df_ledger = rows._current_rows\n",
    "\n",
    "if len(df_ledger) > 0:\n",
    "    df_ledger = df_ledger.sort_values(by=['ts'], ascending=False)\n",
    "    print(f\"üìà Retrieved {len(df_ledger)} chatbot interactions\")\n",
    "    print(f\"üìã Current schema: {list(df_ledger.columns)}\")\n",
    "    \n",
    "    # Check for any missing or extra fields\n",
    "    actual_fields = set(df_ledger.columns)\n",
    "            \n",
    "    print(f\"üöÄ Latest interaction timestamp: {df_ledger.iloc[0]['ts'] if 'ts' in df_ledger.columns else 'N/A'}\")\n",
    "    print(f\"ü§ñ Current model in use: {df_ledger.iloc[0]['model_name'] if 'model_name' in df_ledger.columns else 'N/A'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data found in ledger table\")\n",
    "    df_ledger = pd.DataFrame()\n",
    "\n",
    "# Display the latest 5 interactions\n",
    "df_ledger.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90201333-1163-4382-aa17-9f3e1e07cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA EXPORT FOR FIDDLER AI MONITORING\n",
    "# =============================================================================\n",
    "# Export chatbot interaction data for analysis and monitoring\n",
    "\n",
    "ledger_table = config[\"ASTRA_DB_LEDGER_TABLE_NAME\"]\n",
    "print(f\"üìä Exporting FIRST 100 rows of data from {ledger_table}\")\n",
    "\n",
    "query = f'SELECT * FROM {ledger_table} LIMIT 100'\n",
    "rows = session.execute(query)\n",
    "df_export = rows._current_rows\n",
    "\n",
    "if len(df_export) > 0:\n",
    "    # Sort by timestamp\n",
    "    df_export = df_export.sort_values(by=['ts'])\n",
    "    \n",
    "    # Create baseline dataset (first 50 interactions for model baseline)\n",
    "    baseline_count = min(50, len(df_export))\n",
    "    df_baseline = df_export.iloc[:baseline_count].copy()\n",
    "    df_baseline = df_baseline.drop(columns=['ts'], errors='ignore')  # Remove timestamp for baseline\n",
    "    \n",
    "    # Create events dataset (remaining interactions for monitoring)\n",
    "    df_events = df_export.iloc[baseline_count:].copy()\n",
    "    \n",
    "    # Export to CSV files with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    baseline_filename = f'chatbot_baseline_{timestamp}.csv'\n",
    "    events_filename = f'chatbot_events_{timestamp}.csv'\n",
    "    \n",
    "    df_baseline.to_csv(baseline_filename, index=False)\n",
    "    df_events.to_csv(events_filename, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Exported baseline data: {baseline_filename} ({len(df_baseline)} rows)\")\n",
    "    print(f\"‚úÖ Exported events data: {events_filename} ({len(df_events)} rows)\")\n",
    "    print(f\"üìä Total interactions: {len(df_export)}\")\n",
    "    \n",
    "    # Display export summary\n",
    "    if len(df_export) > 0:\n",
    "        print(f\"üìÖ Date range: {df_export['ts'].min()} to {df_export['ts'].max()}\")\n",
    "        print(f\"ü§ñ Models used: {df_export['model_name'].unique().tolist() if 'model_name' in df_export.columns else 'N/A'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data available for export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd4c0c-3e8a-4ac1-8595-4e4a4789c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAINTENANCE AND CLEANUP OPERATIONS (USE WITH CAUTION)\n",
    "# =============================================================================\n",
    "# These operations can modify or delete data - use only when necessary\n",
    "# All operations are commented out for safety\n",
    "\n",
    "# WARNING: The following operations are DESTRUCTIVE and should only be used\n",
    "# by administrators who understand the consequences\n",
    "\n",
    "# Clean up specific problematic records:\n",
    "# session.execute(\"DELETE FROM fiddler_chatbot_conversation WHERE row_id='-1'\")\n",
    "\n",
    "# Remove legacy tables (ONLY if migration is complete and verified):\n",
    "# session.execute(\"DROP TABLE fiddler_chatbot_history\")\n",
    "\n",
    "# Clear vector store (ONLY for complete rebuild):\n",
    "# vector_table = config[\"ASTRA_DB_TABLE_NAME\"]\n",
    "# session.execute(f\"TRUNCATE TABLE {vector_table}\")\n",
    "\n",
    "# Clear chatbot history (ONLY for fresh start):\n",
    "# ledger_table = config[\"ASTRA_DB_LEDGER_TABLE_NAME\"]\n",
    "# session.execute(f\"TRUNCATE TABLE {ledger_table}\")\n",
    "\n",
    "# Current system status check\n",
    "print(\"üìã Current system status:\")\n",
    "print(f\"   - Vector table:  {config['ASTRA_DB_TABLE_NAME']}\")\n",
    "print(f\"   - Ledger table:  {config['ASTRA_DB_LEDGER_TABLE_NAME']}\")\n",
    "print(f\"   - Current model: {config['OPENAI_LLM_MODEL']}\")\n",
    "print(\"üîê All maintenance operations are commented out for safety\")\n",
    "print(\"‚ö†Ô∏è  Uncomment and execute maintenance operations only if you understand the consequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS FOR CURRENT SYSTEM ANALYSIS\n",
    "# =============================================================================\n",
    "# Helper functions for analyzing the current chatbot system\n",
    "\n",
    "def get_system_health_summary():\n",
    "    \"\"\"Get a comprehensive health summary of the current system\"\"\"\n",
    "    print(\"üè• SYSTEM HEALTH SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check vector store\n",
    "    vector_table = config[\"ASTRA_DB_TABLE_NAME\"]\n",
    "    rows = session.execute(f'SELECT COUNT(*) as count FROM {vector_table}')\n",
    "    vector_count : int= len( list(rows)[0] )\n",
    "    print(f\"üìö Vector Store ({vector_table}): {vector_count} documents\")\n",
    "    \n",
    "    # Check chatbot ledger\n",
    "    ledger_table = config[\"ASTRA_DB_LEDGER_TABLE_NAME\"]\n",
    "    rows = session.execute(f'SELECT COUNT(*) as count FROM {ledger_table}')\n",
    "    ledger_count : int = len( list(rows)[0] )\n",
    "    print(f\"üí¨ Chatbot Interactions ({ledger_table}): {ledger_count} records\")\n",
    "    \n",
    "    if ledger_count > 0:\n",
    "        # Get recent activity - fetch all data and sort in pandas since Cassandra can't ORDER BY non-clustering columns\n",
    "        recent_query = f'SELECT model_name, ts FROM {ledger_table}'\n",
    "        rows = session.execute(recent_query)\n",
    "        df_recent = rows._current_rows\n",
    "        \n",
    "        if len(df_recent) > 0:\n",
    "            # Sort by timestamp in pandas and get the latest\n",
    "            df_recent = df_recent.sort_values(by=['ts'], ascending=False)\n",
    "            latest_row = df_recent.iloc[0]\n",
    "            latest_ts = latest_row['ts']\n",
    "            latest_model = latest_row['model_name']\n",
    "            print(f\"üïê Latest interaction: {latest_ts}\")\n",
    "            print(f\"ü§ñ Latest model used: {latest_model}\")\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Configured model: {config['OPENAI_LLM_MODEL']}\")\n",
    "    print(f\"üß† Embedding model: {config['OPENAI_EMBEDDING_MODEL']}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def get_recent_interactions(limit=5):\n",
    "    \"\"\"Get the most recent chatbot interactions\"\"\"\n",
    "    ledger_table = config[\"ASTRA_DB_LEDGER_TABLE_NAME\"]\n",
    "    query = f'SELECT row_id, prompt, response, model_name, ts FROM {ledger_table}'\n",
    "    \n",
    "    try:\n",
    "        rows = session.execute(query)\n",
    "        df_recent = rows._current_rows\n",
    "        \n",
    "        if len(df_recent) > 0:\n",
    "            # Sort by timestamp in pandas and get the most recent records\n",
    "            df_recent = df_recent.sort_values(by=['ts'], ascending=False)\n",
    "            df_recent = df_recent.head(limit)\n",
    "            \n",
    "            print(f\"üí¨ RECENT INTERACTIONS (Last {len(df_recent)})\")\n",
    "            print(\"=\" * 60)\n",
    "            for i, (_, row) in enumerate(df_recent.iterrows(), 1):\n",
    "                print(f\"{i}. {row['ts']} - {row['model_name']}\")\n",
    "                prompt = str(row['prompt']) if row['prompt'] is not None else \"No prompt\"\n",
    "                response = str(row['response']) if row['response'] is not None else \"No response\"\n",
    "                print(f\"   Q: {prompt[:100]}...\" if len(prompt) > 100 else f\"   Q: {prompt}\")\n",
    "                print(f\"   A: {response[:100]}...\" if len(response) > 100 else f\"   A: {response}\")\n",
    "                print()\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            return df_recent.to_dict('records')\n",
    "        else:\n",
    "            print(\"üí¨ No interactions found\")\n",
    "            return []\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not retrieve recent interactions: {e}\")\n",
    "        return []\n",
    "\n",
    "# Run health summary by default\n",
    "get_system_health_summary()\n",
    "get_recent_interactions(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fad584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Performing vector search for: 'tell me about all the releases after 25.10?'\n",
      "üìä Retrieving top 5 most relevant documents...\n",
      "============================================================\n",
      "‚è±Ô∏è  Search completed in 2.213 seconds\n",
      "üìÑ Retrieved 5 documents\n",
      "============================================================\n",
      "\n",
      "üìã Document 1:\n",
      "   Content length: 2943 characters\n",
      "   Preview: [CONTEXT: Header 1: Release Notes]\n",
      "\n",
      "#### What's New and Improved:  \n",
      "* Performance Analytics (Preview) Embedded in Monitoring Charts\n",
      "* Visualize performance analytics charts as part of the root cause analysis flow for Binary Classification, Multiclass Classification, and Regression models, spanning from confusion matrices, precision recall charts, prediction scatterplots and more.  \n",
      "### Release 24.10 Notes  \n",
      "#### Client Version  \n",
      "Client version 3.3+ is required for the updates and features mentioned in this release.  \n",
      "#### What's New and Improved:  \n",
      "* Support for applied segments in monitoring charts\n",
      "* Create and apply segments dynamically in monitoring charts for exploratory analysis without requiring them to be saved to the model.\n",
      "* User-Defined Feature Impact\n",
      "* The User-Defined Feature Impact enables you to upload custom feature impact for models. This feature addresses several issues reported by our customers, including model artifact size, onboarding complexity, and the need for custom feature impact.\n",
      "* Key highlights\n",
      "* New method: UploadFeatureImpact\n",
      "* Improved Fiddler UI to display uploaded feature impact  \n",
      "### Release 24.9 Note  \n",
      "#### What's New and Improved  \n",
      "* Enhanced access controls\n",
      "* Control access with precision: Manage user access to resources with Role-Based Access Control (RBAC), ensuring the right users have the right permissions.\n",
      "* Simplify user management: Assign roles to users and teams to streamline access control and enhance collaboration. \\*‚â† Protect sensitive resources: Restrict access to sensitive resources, such as models and project settings, with granular permissions.\n",
      "* Work efficiently: Focus on your work without worrying about unauthorized access or data breaches.  \n",
      "### Release 24.8 Notes  \n",
      "#### Release of Fiddler Platform Version 24.8:  \n",
      "* **Performance Analytics Charts (Public Preview)**\n",
      "* Visualize charts to aid in analyzing model performance for Binary Classification, Multiclass Classification, and Regression models.\n",
      "* Leverage applied segments in Performance Analytics charts to explore problematic cohorts of data.  \n",
      "### Release 24.7 Notes  \n",
      "#### What's New and Improved  \n",
      "TBD  \n",
      "### Release 24.6 Notes  \n",
      "#### Release of Fiddler Platform Version 24.6:  \n",
      "* Performance improvements\n",
      "* Improved the performance of various modules / APIs.\n",
      "* Improved observability which can help monitor health and performance of the operations.  \n",
      "#### Client Version  \n",
      "* Client version 3.1.2+ is required for the updates and features mentioned in this release.  \n",
      "### Release 24.5 Notes  \n",
      "#### Release of Fiddler Platform Version 24.5:  \n",
      "* Support for model versions for streamlined model management  \n",
      "#### What's New and Improved:  \n",
      "* **Model Versions**\n",
      "* Efficiently manage related models by creating structured versions, facilitating tasks like retraining and comparison analyses.\n",
      "* Users can maintain model lineage, efficiently manage updates, flexibly modify schemas, and adjust parameters....\n",
      "\n",
      "üìã Document 2:\n",
      "   Content length: 2890 characters\n",
      "   Preview: [CONTEXT: Header 1: Release Notes]\n",
      "\n",
      "# Release Notes  \n",
      "### Release 25.13 Notes  \n",
      "**Fixes and Security Updates**  \n",
      "* **Security Updates**: Applied routine security patches and version updates to application frameworks to stay up-to-date with the latest improvements.\n",
      "* **Alerts UI Consistency**: Fixed various display inconsistencies in the Alerts interface to improve user experience and visual consistency across the platform.  \n",
      "### Release 25.12 Notes  \n",
      "#### **What's New and Improved**  \n",
      "* **Concurrent Enrichment Processing**\n",
      "* Introduced parallel processing for independent enrichment operations, significantly improving performance when multiple enrichments are applied to your LLM data\n",
      "* _Performance Impact:_ Reduces overall enrichment processing time by up to 70% when using multiple enrichments (e.g., combining PII detection, toxicity analysis, and sentiment scoring)\n",
      "* _Benefit:_ Faster data processing enables near real-time monitoring for high-volume LLM applications, reducing the delay between data ingestion and actionable insights\n",
      "* _Note:_ This feature is currently in controlled rollout. Contact your customer success manager if you'd like early access  \n",
      "#### **Fixes and Security Updates**  \n",
      "* **Security Updates**: Applied routine security patches and version updates to application frameworks to stay up-to-date with the latest improvements.  \n",
      "### Release 25.11 Notes  \n",
      "**Fixes and Security Updates**  \n",
      "* **Security Updates**: Applied routine security patches and version updates to application frameworks to stay up-to-date with the latest improvements.  \n",
      "### Release 25.10 Notes  \n",
      "#### **What's New and Improved**  \n",
      "* **Custom LLM Enrichment & Evaluations Enhancements**\n",
      "* _Improved Determinism:_ Temperature parameter now defaults to 0 for classification use cases, ensuring more consistent and repeatable results\n",
      "* _Enhanced Flexibility:_ The Evaluations endpoint now accepts a temperature parameter, matching the configuration options available in Enrichment\n",
      "* _Benefit:_ Teams can achieve more predictable classification outputs while maintaining the flexibility to adjust temperature when needed for specific use cases\n",
      "* [Explore Technical Reference ‚Üí](../technical-reference/api-methods-30.md#custom-llm-classifier-private-preview)\n",
      "* **Fiddler Fast Trust Faithfulness v2.4.1**\n",
      "* _Performance Boost:_ Up to 150ms faster processing on longer input texts\n",
      "* _Benefit:_ Reduced latency for faithfulness checks on documents and extended conversations, enabling more responsive LLM monitoring at scale\n",
      "* _Impact:_ Particularly beneficial for applications processing lengthy contexts or high-volume document analysis workflows  \n",
      "### Release 25.9 Notes  \n",
      "#### **What's New and Improved**  \n",
      "* **Custom Webhook Support for Alert Notifications**\n",
      "* Extended webhook integration capabilities beyond Slack and Microsoft Teams to support any webhook provider\n",
      "* _Key Features:_...\n",
      "\n",
      "üìã Document 3:\n",
      "   Content length: 3027 characters\n",
      "   Preview: [CONTEXT: Header 1: Release Notes]\n",
      "\n",
      "#### Client Version  \n",
      "* Client version 3.1.2+ is required for the updates and features mentioned in this release.  \n",
      "### Release 24.5 Notes  \n",
      "#### Release of Fiddler Platform Version 24.5:  \n",
      "* Support for model versions for streamlined model management  \n",
      "#### What's New and Improved:  \n",
      "* **Model Versions**\n",
      "* Efficiently manage related models by creating structured versions, facilitating tasks like retraining and comparison analyses.\n",
      "* Users can maintain model lineage, efficiently manage updates, flexibly modify schemas, and adjust parameters.\n",
      "* **See**: [Model Versions](../product-guide/monitoring-platform/model-versions.md) for more information.\n",
      "* **Airgapped Enrichments (alpha)**\n",
      "* For privacy sensitive use cases, all data getting enriched stays within customer premises.\n",
      "* **New Deployment Base Images**\n",
      "* We have added new deployment base images to support model versioning.\n",
      "* See [here](../product-guide/explainability/flexible-model-deployment/).  \n",
      "**Client Version**  \n",
      "Client version 3.1.0+ is required for the updates and features mentioned in this release.  \n",
      "### Release 24.4 Notes  \n",
      "#### Release of Fiddler Platform Version 24.4:  \n",
      "* UMAP UI changes\n",
      "* SSO integration changes\n",
      "* New concept: **Environments**\n",
      "* Fundamental changes to product concepts  \n",
      "#### What's New and Improved:  \n",
      "* **UMAP UI**\n",
      "* Vertical scrolling instead of horizontal scrolling for data cards\n",
      "* \"View More\" option to open data cards in maximized modal\n",
      "* Ability to toggle between data cards in the maximized modal\n",
      "* **SSO integration changes**\n",
      "* Fiddler now integrates with Azure AD SSO, allowing you to leverage existing user roles for access control within Fiddler. This eliminates the need for manual user creation and simplifies user management within your organization. See [Azure AD SSO Support](../administration/access-control/single-sign-on-with-azure-ad.md) for details\n",
      "* **Environments**\n",
      "* Each Model now has two environments (Pre-Production and Production) used to house data in different ways.\n",
      "* A Model's Pre-Production environment is used to house non-time series data (Datasets).\n",
      "* A Model's Production environment is used to house time series data.\n",
      "* **Product concept changes**\n",
      "* Datasets are no longer stored at the Project level. Instead, they're stored at the Model level under the Pre-Production Environment.\n",
      "* The Model Details page has been updated with a new design.  \n",
      "**Client Version**  \n",
      "Client version 3.0+ is required for the updates and features mentioned in this release.  \n",
      "#### Client 3.x Release:  \n",
      "We are launching Client 3.x, this is revamped client 2.x as we move to more object oriented based methods. This means, any pipeline setup in client 2.x would eventually be required to upgrade to the new methods. **Client 2.x will sunset approximately 6 months post this release.** Please take a look at the below resources to help you understand client 3.x and also how you can upgrade your pipelines:  \n",
      "* [API Documentation](../technical-reference/api-methods-30.md)...\n",
      "\n",
      "üìã Document 4:\n",
      "   Content length: 2995 characters\n",
      "   Preview: [CONTEXT: Header 1: Release Notes]\n",
      "\n",
      "**How it helps you**  \n",
      "* Faster processing times for streaming data\n",
      "* Reduced latency for real-time monitoring applications\n",
      "* No delays from large batch upload operations  \n",
      "**How It Works**  \n",
      "Streaming events now flow through a separate, high-priority processing lane‚Äîsimilar to an HOV lane on a highway‚Äîbypassing any congestion from batch operations. This feature works automatically with your existing implementation. No configuration changes required.  \n",
      "### Release 25.2 Notes  \n",
      "#### What's New and Improved  \n",
      "We have added Token Count as a new addition to Fiddler's out-of-the-box [enrichments](../product-guide/llm-monitoring/selecting-enrichments.md). Token count visibility is a key factor for monitoring and optimizing LLM applications. This enrichment is particularly useful for cost analysis, as it tracks API usage and helps teams understand the financial implications of their LLM usage. It also aids in identifying performance issues related to token limits and supports system health monitoring by detecting unusual patterns or truncated responses. Teams can use token metrics to optimize prompts for efficiency and quality while understanding usage patterns across their application. Combined with existing quality metrics, token counts offer a more complete view of LLM system performance and help teams make data-driven decisions about their prompt engineering and resource allocation.  \n",
      "#### Client Version  \n",
      "Python client version is updated to [3.8](python-client-history.md#380) and includes new support for updating additional parameters of [AlertRules](../technical-reference/api-methods-30.md#alertrule) including `warning_threshold`, `critical_threshold`, and `evaluation_delay`.  \n",
      "### Release 25.1 Notes  \n",
      "#### What's New and Improved  \n",
      "**Introducing Fiddler Guardrails!**  \n",
      "Fiddler AI has introduced Fiddler Guardrails, a new feature that extends the Fiddler Trust Service and is designed to enhance the safety and security of Large Language Model (LLM) applications. This tool proactively detects and mitigates risks such as hallucinations and prompt injection attacks, ensuring more reliable and trustworthy AI operations. Organizations can confidently deploy LLM applications with improved oversight and protection by integrating Fiddler Guardrails. You can see the full announcement [here](https://www.fiddler.ai/blog/introducing-fiddler-guardrails) for a comprehensive overview of this feature.  \n",
      "**Improvements**  \n",
      "This release includes updates focused on improving system performance, stability, and scalability. These improvements ensure a smoother user experience and provide a more robust platform for future developments.  \n",
      "**Guardrails Endpoint Change**  \n",
      "This release updates the following Guardrails REST API endpoints. The [Guardrails guide](../product-guide/llm-monitoring/guardrails.md) provides detailed usage information.  \n",
      "| Guardrail Service            | Previous Endpoint           | Current Endpoint          |...\n",
      "\n",
      "üìã Document 5:\n",
      "   Content length: 2898 characters\n",
      "   Preview: [CONTEXT: Header 1: Release Notes]\n",
      "\n",
      "* [Explore Example Usage ‚Üí](../product-guide/llm-monitoring/enrichments-private-preview.md#custom-llm-classifier-private-preview)  \n",
      "#### Fixes and Security Updates  \n",
      "* **Security Updates**: Applied routine security patches and version updates to application frameworks to stay up-to-date with the latest improvements.  \n",
      "#### Documentation Updates  \n",
      "* **Removed Deployment Guide**: The Deployment Guide is no longer relevant to Fiddler SaaS and managed SaaS offerings.  \n",
      "### Release 25.5 Notes  \n",
      "#### Improvements  \n",
      "* **Baseline Name Length**: Increased the maximum allowed characters from 30 to 256. This change enables more descriptive baseline names for complex projects with multiple models and datasets.\n",
      "* _Action Required_: None. Existing baselines remain unchanged.\n",
      "* [View Baseline Documentation ‚Üí](../technical-reference/python-client-guides/publishing-production-data/creating-a-baseline-dataset.md)\n",
      "* **Enhanced Job Error Messages**: Error messages during metrics aggregation now specifically identify which step in the data ingestion process failed, helping you troubleshoot pipeline issues faster.\n",
      "* _Benefit_: Reduces debugging time by pinpointing in which step jobs are failing.  \n",
      "#### Fixes and Security Updates  \n",
      "* **Security Updates**: Applied routine security patches to container images and application frameworks to address recent vulnerabilities.\n",
      "* **Homepage Cache Timestamp**: Fixed an issue where cached dashboard data would display incorrect \"Last Updated\" timestamps, leading to confusion about data freshness.  \n",
      "#### Documentation Updates  \n",
      "* **Streamlined Structure**: Reorganized documentation with improved navigation paths between related topics.\n",
      "* _New Section_: Consolidated technical guides and API references into the \"Technical Reference\" section.\n",
      "* [Explore Technical References ‚Üí](../technical-reference/api-methods-30.md)  \n",
      "### Release 25.4 Notes  \n",
      "#### What's New and Improved  \n",
      "#### Now Available in Public Preview  \n",
      "* **UI-based Model Onboarding with Draft Mode**: Iteratively refine your model schema before publishing. Validate sample data, collaborate with your team, and deploy with confidence. This streamlines the model deployment process for faster time-to-value. See our new [Model Guides](../product-guide/model-ui/) for details and best practices.  \n",
      "#### Improvements  \n",
      "* **Enhanced Charts Framework**: Implemented significant improvements to our charting system, delivering more consistent rendering and reliable performance across all dashboards and visualizations.\n",
      "* **Fast Faithfulness Trust Model Enhancements**: Improved classification accuracy overall by 23% and reduced the Q\\&A benchmark error rate by 36%. For technical details, see our [Fiddler Trust Model documentation](../product-guide/llm-monitoring/enrichments-private-preview.md#faithfulness-private-preview).  \n",
      "#### Fixes and Security Updates...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Cassandra as CassandraVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.cluster import Cluster\n",
    "import time\n",
    "\n",
    "# =============================================================================\n",
    "# VECTOR SIMILARITY SEARCH UTILITY\n",
    "# =============================================================================\n",
    "# This cell replicates the vector search functionality from the main chatbot\n",
    "# to allow debugging and testing of retrieval queries\n",
    "\n",
    "\"\"\"\n",
    "üöÄ Vector Search Utility Ready!\n",
    "üìù Example usage:\n",
    "    documents = test_vector_search('What is Fiddler?')\n",
    "    documents = test_vector_search('How to monitor models?', k=5)\n",
    "    documents = test_vector_search('API documentation', k=3, show_details=False)\n",
    "\"\"\"\n",
    "\n",
    "def test_vector_search(query: str, k: int = 3, show_details: bool = True):\n",
    "    \"\"\"\n",
    "    Perform vector similarity search using the same logic as the main chatbot.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query (e.g., \"What is Fiddler?\")\n",
    "        k (int): Number of documents to retrieve (default: 3, same as chatbot)\n",
    "        show_details (bool): Whether to show detailed document content\n",
    "    \n",
    "    Returns:\n",
    "        List of retrieved documents\n",
    "    \"\"\"\n",
    "    print(f\"üîç Performing vector search for: '{query}'\")\n",
    "    print(f\"üìä Retrieving top {k} most relevant documents...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set up embeddings using the same configuration as chatbot\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=config[\"OPENAI_EMBEDDING_MODEL\"], \n",
    "        dimensions=1536\n",
    "    )\n",
    "    \n",
    "    # Create a new session specifically for vector search (without pandas_factory)\n",
    "    # The existing session has pandas_factory which conflicts with LangChain's expectations\n",
    "    cloud_config = {\n",
    "        'secure_connect_bundle': '../'+config[\"ASTRA_DB_SECURE_BUNDLE_PATH\"]\n",
    "    }\n",
    "    \n",
    "    ASTRA_DB_APPLICATION_TOKEN = os.environ.get('ASTRA_DB_APPLICATION_TOKEN')\n",
    "    if not ASTRA_DB_APPLICATION_TOKEN:\n",
    "        raise ValueError(\"ASTRA_DB_APPLICATION_TOKEN environment variable is required\")\n",
    "    \n",
    "    # Create a separate connection for vector operations (without custom row factory)\n",
    "    auth_provider = PlainTextAuthProvider(\"token\", ASTRA_DB_APPLICATION_TOKEN)\n",
    "    vector_cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "    vector_session = vector_cluster.connect()\n",
    "    vector_session.set_keyspace(config[\"ASTRA_DB_KEYSPACE\"])\n",
    "    \n",
    "    # Create Cassandra vector store using the dedicated session\n",
    "    vector_store = CassandraVectorStore(\n",
    "        embedding=embeddings,\n",
    "        session=vector_session,\n",
    "        keyspace=config[\"ASTRA_DB_KEYSPACE\"],\n",
    "        table_name=config[\"ASTRA_DB_TABLE_NAME\"]\n",
    "    )\n",
    "    \n",
    "    # Perform similarity search with timing\n",
    "    start_time = time.time()\n",
    "    documents = vector_store.similarity_search(query, k=k)\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚è±Ô∏è  Search completed in {search_time:.3f} seconds\")\n",
    "    print(f\"üìÑ Retrieved {len(documents)} documents\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"‚ö†Ô∏è  No documents found for the query\")\n",
    "        return []\n",
    "    \n",
    "    # Display results\n",
    "    for i, doc in enumerate(documents, 1):\n",
    "        print(f\"\\nüìã Document {i}:\")\n",
    "        print(f\"   Content length: {len(doc.page_content)} characters\")\n",
    "        \n",
    "        if show_details:\n",
    "            # Show first 200 characters of content\n",
    "            content_preview = doc.page_content #.replace('\\n', ' ')\n",
    "            print(f\"   Preview: {content_preview}...\")\n",
    "            \n",
    "            # Show metadata if available\n",
    "            if hasattr(doc, 'metadata') and doc.metadata:\n",
    "                print(f\"   Metadata: {doc.metadata}\")\n",
    "        else:\n",
    "            # Just show first 100 characters\n",
    "            content_preview = doc.page_content #.replace('\\n', ' ')\n",
    "            print(f\"   Preview: {content_preview}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    vector_cluster.shutdown()\n",
    "    return documents\n",
    "\n",
    "\n",
    "test_documents = test_vector_search(\"tell me about all the releases after 25.10?\", k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de01ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
