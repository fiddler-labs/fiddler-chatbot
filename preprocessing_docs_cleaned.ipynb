{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a221e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "import re\n",
    "from scipy import spatial \n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e1f17-8e72-43f7-8d99-de0e8e3afaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ee26e-03bc-49eb-8c74-4da5339d2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def generate_embeddings(chunked_doc, tiktoken_encoding = \"cl100k_base\", token_limit = 8000 )\n",
    "    global EMBEDDING_MODEL = \"text-embedding-ada-002\"  \n",
    "    encoding = tiktoken.get_encoding(tiktoken_encoding)\n",
    "    embeddings=[]\n",
    "    for i in range(len(chunked_doc)):\n",
    "        fdl_doc_token_list = encoding.encode(chunked_doc[i])\n",
    "        if(len(fdl_doc_token_list)<token_limit):\n",
    "            response = openai.Embedding.create(model=EMBEDDING_MODEL, input=chunked_doc[i])\n",
    "            embeddings.append(response[\"data\"][0][\"embedding\"])\n",
    "    return embeddings\n",
    "\n",
    "def chunked_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    max_tokens: int = 2000,\n",
    ") -> str:\n",
    "    \"\"\"Truncate a string to a maximum number of tokens.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    encoded_string = encoding.encode(string)\n",
    "    chunked_string = [encoding.decode(encoded_string[i:i+max_tokens]) for i in range(0, len(encoded_string), max_tokens)]\n",
    "    return chunked_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b1b58-85bc-492d-b7fe-4d1c45664471",
   "metadata": {},
   "source": [
    "### creating embeddings for docs downloaded from readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd988d-8d2b-46b9-8a3d-b7f18a920280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the path to where your downloaded folder is and choose the version of the docs you want to process\n",
    "chunked_doc = []\n",
    "for root, dirs, files in os.walk(\"./fiddler-2023-10-16/v23.4\"):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        if path[-3:] == '.md':\n",
    "            with open(path,'r') as f:\n",
    "                file_str = f.read()\n",
    "                chunked_doc.append(file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128aa5b4-c398-4f26-b06b-c019f4456e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find and remove hidden pages\n",
    "pattern = r'hidden:\\s*(\\w+)'\n",
    "\n",
    "for doc in chunked_doc:\n",
    "    match = re.search(pattern, doc)\n",
    "    if match and match.group(1) == \"true\":\n",
    "        chunked_doc.remove(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee60d6-0090-465c-b353-b29797915e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will append page slugs to every chunk\n",
    "slug_pattern = r'slug:\\s*\"(.*?)\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7fabd-f713-432c-9ffe-9c348f87cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunking docs to 750 tokens\n",
    "\n",
    "token_lim_doc = []\n",
    "for doc in chunked_doc:\n",
    "    if num_tokens(doc) > 750:\n",
    "        chunked_list = chunked_string(doc, max_tokens=750)\n",
    "        chunked_doc_slug = re.search(slug_pattern, chunked_list[0]).group(0)\n",
    "        for i in range(1, len(chunked_list)):\n",
    "            chunked_list[i] = chunked_doc_slug + ' ' + chunked_list[i]\n",
    "        \n",
    "        token_lim_doc += chunked_list\n",
    "    else:\n",
    "        token_lim_doc.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02b4d7-ffe5-4610-95f5-9d6cec911baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embeddings(token_lim_doc)\n",
    "df = pd.DataFrame({\"text\": chunked_doc, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d7c976-16d3-47ba-973a-e806151cbdfd",
   "metadata": {},
   "source": [
    "### to clean html text [optional] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3cb9cd-3cb4-4dce-b2ff-021978a5d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is HTML text.\n"
     ]
    }
   ],
   "source": [
    "#!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_text = \"<p>This is <b>HTML</b> text.</p>\"\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "clean_text = soup.get_text()\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b37598-2c26-44f3-a931-a9510fcf2a91",
   "metadata": {},
   "source": [
    "### Example of adding a caveat to already existing docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7346a177-a308-4d02-b56c-e924f69c2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 1\n",
    "Caveats = \"\"\"Currently, only the following fields in [fdl.ModelInfo()](ref:fdlmodelinfo) can be updated:\n",
    "> \n",
    "> - `custom_explanation_names`\n",
    "> - `preferred_explanation_method`\n",
    "> - `display_name`\n",
    "> - `description` \"\"\"\n",
    "\n",
    "chunked_doc = [Caveats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f97a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 2\n",
    "Caveats = \"Once you have added a model on the Fiddler platform using a specific model info object, that is fdl.ModelInfo, you cannot modify aspects such as features, inputs, outputs, model task etc. specified in the model info object. Currently, if you want to change fundamental details about a modelinfo object, then it is advised to create/add a new model with a new modelinfo object.\"\n",
    "chunked_doc = [Caveats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2307acd-9b22-4d1a-b79e-183bfc27b885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Custom metrics is an upcoming feature and it i...</td>\n",
       "      <td>[-0.017716489732265472, -0.0035160724073648453...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Custom metrics is an upcoming feature and it i...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.017716489732265472, -0.0035160724073648453...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_embeddings(chunked_doc, tiktoken_encoding = \"cl100k_base\", token_limit = 8000 )\n",
    "    global EMBEDDING_MODEL = \"text-embedding-ada-002\"  \n",
    "    encoding = tiktoken.get_encoding(tiktoken_encoding)\n",
    "    embeddings=[]\n",
    "    for i in range(len(chunked_doc)):\n",
    "        fdl_doc_token_list = encoding.encode(chunked_doc[i])\n",
    "        if(len(fdl_doc_token_list)<token_limit):\n",
    "            response = openai.Embedding.create(model=EMBEDDING_MODEL, input=chunked_doc[i])\n",
    "            embeddings.append(response[\"data\"][0][\"embedding\"])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b33fd4-33c9-4524-8fc4-28cb5d7bbd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embeddings(chunked_doc)\n",
    "df = pd.DataFrame({\"text\": chunked_doc, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeebce1-f878-43ed-b8ac-92ec5138255e",
   "metadata": {},
   "source": [
    "### finding urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a8afb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Fiddler's role in the ML lifecycle is to monitor, explain, analyze, and improve ML deployments at enterprise scale.\n",
    "It provides contextual insights at any stage of the ML lifecycle, helps improve predictions, increases transparency and fairness, \n",
    "and optimizes business revenue. \n",
    "Reference: [Fiddler Simple Monitoring Quick Start Guide](https://docs.fiddler.ai/docs/Fiddler_Quickstart_Simple_Monitoring)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "055bfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = re.findall(url_pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7a4370c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://docs.fiddler.ai/docs/Fiddler_Quickstart_Simple_Monitoring']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
