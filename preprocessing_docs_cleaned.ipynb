{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8359b3-5822-4ae4-8f4c-2790033cb519",
   "metadata": {},
   "source": [
    "## Follow these steps to reload the vector index, currently running in DataStax\n",
    "* Download files from readme - go to configurations - project management and export docs.  You will get a download of ALL versions of fiddler documentation - you only need 23.x (latest).  Copy this into /documenation_data/23.x\n",
    "* Make sure you copy in the ChangelongPosts (release notes) into the 23.x directory you plan to process\n",
    "* you will have to clean up hidden docs that are in 23.x - this is done further down in this notebook\n",
    "* you will need to add the caveats from old 23.x docs into new ones\n",
    "* after preprocessing is done, you will need to run \"loader_cassandra_vector_index.ipynb\" to reload the vector index table.\n",
    "* the \"query_cassandra.ipynb\" notebook has a cell to TRUNCATE the \"fiddler_doc_snippets_openai\" table before reloading it\n",
    "\n",
    "### Notes and Hints\n",
    "\n",
    "jupyter nbconvert *.ipynb --to markdown\n",
    "\n",
    "The QuickStart .md files from ReadMe should have the google colab notebook content appended to the end of them in the /23.x/QuickStart Notebooks folder.  Make sure the new content from the colab notebooks gets appeneded for each release.  you can use this code below to assist with this effort.\n",
    "\n",
    "### Here is possible code to script the appending of the google colab markdown notebooks to the quickstart docs pages\n",
    "\n",
    "```python\n",
    "for root, dirs, files in os.walk(“./fiddler-2023-8-15/v1.8/QuickStart Notebooks”):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        if path[-3:] == ‘.md’:\n",
    "            with open(path,‘r’) as f:\n",
    "                file_str = f.read()\n",
    "            ipynb_links = re.search(ipynb_slug, file_str)\n",
    "            if ipynb_links:\n",
    "                with open(“./fiddler-2023-8-15/quickstart/“+ipynb_links.group(1)+“.md”) as l:\n",
    "                    QS = l.read()\n",
    "                with open(path, ‘a’) as f:\n",
    "                    f.write(QS)\n",
    "                print(ipynb_links.group(1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a221e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "import re\n",
    "from scipy import spatial \n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13e1f17-8e72-43f7-8d99-de0e8e3afaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "release_num = '23.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034ee26e-03bc-49eb-8c74-4da5339d2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# def generate_embeddings(chunked_doc, tiktoken_encoding = \"cl100k_base\", token_limit = 8000 )\n",
    "#     global EMBEDDING_MODEL = \"text-embedding-ada-002\"  \n",
    "#     encoding = tiktoken.get_encoding(tiktoken_encoding)\n",
    "#     embeddings=[]\n",
    "#     for i in range(len(chunked_doc)):\n",
    "#         fdl_doc_token_list = encoding.encode(chunked_doc[i])\n",
    "#         if(len(fdl_doc_token_list)<token_limit):\n",
    "#             response = openai.Embedding.create(model=EMBEDDING_MODEL, input=chunked_doc[i])\n",
    "#             embeddings.append(response[\"data\"][0][\"embedding\"])\n",
    "#     return embeddings\n",
    "\n",
    "def chunked_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    max_tokens: int = 2000,\n",
    ") -> str:\n",
    "    \"\"\"Truncate a string to a maximum number of tokens.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    encoded_string = encoding.encode(string)\n",
    "    chunked_string = [encoding.decode(encoded_string[i:i+max_tokens]) for i in range(0, len(encoded_string), max_tokens)]\n",
    "    return chunked_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b1b58-85bc-492d-b7fe-4d1c45664471",
   "metadata": {},
   "source": [
    "### creating embeddings for docs downloaded from readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cadd988d-8d2b-46b9-8a3d-b7f18a920280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the path to where your downloaded folder is and choose the version of the docs you want to process\n",
    "chunked_doc = []\n",
    "for root, dirs, files in os.walk(f'documentation_data/v{release_num}'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        if path[-3:] == '.md':\n",
    "            with open(path,'r') as f:\n",
    "                file_str = f.read()\n",
    "                chunked_doc.append(file_str)\n",
    "                \n",
    "len(chunked_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128aa5b4-c398-4f26-b06b-c019f4456e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find and remove hidden pages\n",
    "pattern = r'hidden:\\s*(\\w+)'\n",
    "\n",
    "for doc in chunked_doc:\n",
    "    match = re.search(pattern, doc)\n",
    "    if match and match.group(1) == \"true\":\n",
    "        chunked_doc.remove(doc)\n",
    "        \n",
    "len(chunked_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ee60d6-0090-465c-b353-b29797915e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will append page slugs to every chunk\n",
    "slug_pattern = r'slug:\\s*\"(.*?)\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f7fabd-f713-432c-9ffe-9c348f87cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunking docs to 750 tokens\n",
    "\n",
    "token_lim_doc = []\n",
    "for doc in chunked_doc:\n",
    "    if num_tokens(doc) > 750:\n",
    "        chunked_list = chunked_string(doc, max_tokens=750)\n",
    "        chunked_doc_slug = re.search(slug_pattern, chunked_list[0]).group(0)\n",
    "        for i in range(1, len(chunked_list)):\n",
    "            chunked_list[i] = chunked_doc_slug + ' ' + chunked_list[i]\n",
    "        \n",
    "        token_lim_doc += chunked_list\n",
    "    else:\n",
    "        token_lim_doc.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf3db71-ccaf-44cc-b8a4-e03e043c55f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>package.py for R based models```python\\nimport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Once you have added a model on the Fiddler pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Custom metrics is an upcoming feature and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Re-uploading in Fiddler essentially means havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Currently, only the following fields in [fdl.M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>AI has been in the limelight thanks to ‌recent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LLM means large language model.  A large langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The term generative AI, or GenAI, also is clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FM, or FMs, means Foundation Models.  Foundati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "279  package.py for R based models```python\\nimport...\n",
       "280  Once you have added a model on the Fiddler pla...\n",
       "281  Custom metrics is an upcoming feature and it i...\n",
       "282  Re-uploading in Fiddler essentially means havi...\n",
       "320  Currently, only the following fields in [fdl.M...\n",
       "321  AI has been in the limelight thanks to ‌recent...\n",
       "6    LLM means large language model.  A large langu...\n",
       "7    The term generative AI, or GenAI, also is clos...\n",
       "8    FM, or FMs, means Foundation Models.  Foundati..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in old caveats from previous version and output them to a new file\n",
    "old_df = pd.read_csv('documentation_data/latest_v_23-4_tk750_fixurls2.csv')\n",
    "caveats_df = old_df[~old_df['text'].str.contains('slug', case=False)]\n",
    "caveats_df = caveats_df.drop(columns=['embedding'])\n",
    "caveats_df.to_csv(f'documentation_data/v{release_num}/caveats.csv', index=False)\n",
    "\n",
    "caveats_df.loc[len(caveats_df.index)] = ['LLM means large language model.  A large language model (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content.']\n",
    "caveats_df.loc[len(caveats_df.index)] = ['The term generative AI, or GenAI, also is closely connected with LLMs, which are, in fact, a type of generative AI that has been specifically architected to help generate text-based content.']\n",
    "caveats_df.loc[len(caveats_df.index)] = ['FM, or FMs, means Foundation Models.  Foundation Models are the same as large language models.']\n",
    "\n",
    "caveats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad02b4d7-ffe5-4610-95f5-9d6cec911baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---\\ntitle: \"fdl.FiddlerApi\"\\nslug: \"client-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slug: \"client-setup\"     url=URL,\\n    org_id=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---\\ntitle: \"Customer Churn Prediction\"\\nslug:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slug: \"customer-churn-prediction\"  \"https://fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slug: \"customer-churn-prediction\" ca-1.png\",\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Currently, only the following fields in [fdl.M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>AI has been in the limelight thanks to ‌recent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>LLM means large language model.  A large langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>The term generative AI, or GenAI, also is clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>FM, or FMs, means Foundation Models.  Foundati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    ---\\ntitle: \"fdl.FiddlerApi\"\\nslug: \"client-se...\n",
       "1    slug: \"client-setup\"     url=URL,\\n    org_id=...\n",
       "2    ---\\ntitle: \"Customer Churn Prediction\"\\nslug:...\n",
       "3    slug: \"customer-churn-prediction\"  \"https://fi...\n",
       "4    slug: \"customer-churn-prediction\" ca-1.png\",\\n...\n",
       "..                                                 ...\n",
       "347  Currently, only the following fields in [fdl.M...\n",
       "348  AI has been in the limelight thanks to ‌recent...\n",
       "349  LLM means large language model.  A large langu...\n",
       "350  The term generative AI, or GenAI, also is clos...\n",
       "351  FM, or FMs, means Foundation Models.  Foundati...\n",
       "\n",
       "[352 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embeddings = generate_embeddings(token_lim_doc)\n",
    "#df = pd.DataFrame({\"text\": chunked_doc, \"embedding\": embeddings})\n",
    "df = pd.DataFrame({\"text\": token_lim_doc})\n",
    "df = pd.concat([df,caveats_df], ignore_index=True)\n",
    "df.to_csv(f'documentation_data/vector_index_feed_{release_num}.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae67773d-b69c-4ef6-ade0-0776c9bac982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>---\\ntitle: \"Release 22.11 Notes\"\\nslug: \"rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>---\\ntitle: \"Release 23.2 Notes\"\\nslug: \"relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>---\\ntitle: \"Release 23.6 Notes\"\\nslug: \"relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>---\\ntitle: \"Release 23.3 Notes\"\\nslug: \"relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>---\\ntitle: \"Release 22.12 Notes\"\\nslug: \"rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>---\\ntitle: \"Release 23.4 Notes\"\\nslug: \"relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>---\\ntitle: \"Release 23.5 Notes\"\\nslug: \"relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>---\\ntitle: \"Release 23.1 Notes\"\\nslug: \"2023-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>---\\ntitle: \"Embedding Visualization Chart Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>AI has been in the limelight thanks to ‌recent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "70   ---\\ntitle: \"Release 22.11 Notes\"\\nslug: \"rele...\n",
       "71   ---\\ntitle: \"Release 23.2 Notes\"\\nslug: \"relea...\n",
       "72   ---\\ntitle: \"Release 23.6 Notes\"\\nslug: \"relea...\n",
       "73   ---\\ntitle: \"Release 23.3 Notes\"\\nslug: \"relea...\n",
       "74   ---\\ntitle: \"Release 22.12 Notes\"\\nslug: \"rele...\n",
       "75   ---\\ntitle: \"Release 23.4 Notes\"\\nslug: \"relea...\n",
       "76   ---\\ntitle: \"Release 23.5 Notes\"\\nslug: \"relea...\n",
       "77   ---\\ntitle: \"Release 23.1 Notes\"\\nslug: \"2023-...\n",
       "195  ---\\ntitle: \"Embedding Visualization Chart Cre...\n",
       "348  AI has been in the limelight thanks to ‌recent..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.contains('release', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d7c976-16d3-47ba-973a-e806151cbdfd",
   "metadata": {},
   "source": [
    "### to clean html text [optional] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3cb9cd-3cb4-4dce-b2ff-021978a5d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is HTML text.\n"
     ]
    }
   ],
   "source": [
    "#!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_text = \"<p>This is <b>HTML</b> text.</p>\"\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "clean_text = soup.get_text()\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b37598-2c26-44f3-a931-a9510fcf2a91",
   "metadata": {},
   "source": [
    "### Example of adding a caveat to already existing docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7346a177-a308-4d02-b56c-e924f69c2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 1\n",
    "Caveats = \"\"\"Currently, only the following fields in [fdl.ModelInfo()](ref:fdlmodelinfo) can be updated:\n",
    "> \n",
    "> - `custom_explanation_names`\n",
    "> - `preferred_explanation_method`\n",
    "> - `display_name`\n",
    "> - `description` \"\"\"\n",
    "\n",
    "chunked_doc = [Caveats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f97a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 2\n",
    "Caveats = \"Once you have added a model on the Fiddler platform using a specific model info object, that is fdl.ModelInfo, you cannot modify aspects such as features, inputs, outputs, model task etc. specified in the model info object. Currently, if you want to change fundamental details about a modelinfo object, then it is advised to create/add a new model with a new modelinfo object.\"\n",
    "chunked_doc = [Caveats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2307acd-9b22-4d1a-b79e-183bfc27b885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Custom metrics is an upcoming feature and it i...</td>\n",
       "      <td>[-0.017716489732265472, -0.0035160724073648453...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Custom metrics is an upcoming feature and it i...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.017716489732265472, -0.0035160724073648453...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_embeddings(chunked_doc, tiktoken_encoding = \"cl100k_base\", token_limit = 8000 )\n",
    "    global EMBEDDING_MODEL = \"text-embedding-ada-002\"  \n",
    "    encoding = tiktoken.get_encoding(tiktoken_encoding)\n",
    "    embeddings=[]\n",
    "    for i in range(len(chunked_doc)):\n",
    "        fdl_doc_token_list = encoding.encode(chunked_doc[i])\n",
    "        if(len(fdl_doc_token_list)<token_limit):\n",
    "            response = openai.Embedding.create(model=EMBEDDING_MODEL, input=chunked_doc[i])\n",
    "            embeddings.append(response[\"data\"][0][\"embedding\"])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b33fd4-33c9-4524-8fc4-28cb5d7bbd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embeddings(chunked_doc)\n",
    "df = pd.DataFrame({\"text\": chunked_doc, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeebce1-f878-43ed-b8ac-92ec5138255e",
   "metadata": {},
   "source": [
    "### finding urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a8afb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Fiddler's role in the ML lifecycle is to monitor, explain, analyze, and improve ML deployments at enterprise scale.\n",
    "It provides contextual insights at any stage of the ML lifecycle, helps improve predictions, increases transparency and fairness, \n",
    "and optimizes business revenue. \n",
    "Reference: [Fiddler Simple Monitoring Quick Start Guide](https://docs.fiddler.ai/docs/Fiddler_Quickstart_Simple_Monitoring)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "055bfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = re.findall(url_pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7a4370c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://docs.fiddler.ai/docs/Fiddler_Quickstart_Simple_Monitoring']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
