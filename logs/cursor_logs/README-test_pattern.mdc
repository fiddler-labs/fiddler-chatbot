---
description: 
globs: 
alwaysApply: true
---
# Cursor Test Execution Logs

This directory contains logs of all test executions performed by the Cursor AI assistant to prevent hallucinated test results and ensure accountability.

## Purpose

- **Prevent Hallucinated Tests**: Ensures all test runs are real executions, not fake print statements
- **Audit Trail**: Provides complete record of test commands, outputs, and results
- **Debugging Support**: Captures complete error traces and failure information
- **Verification**: Allows manual verification of test results and assertions

## Log File Format

Log files follow the naming convention: `test_run_YYYY-MM-DD_HH-MM-SS.log`

Each log file contains:

- Timestamp of execution
- Full command executed
- Test file path and working directory
- Complete stdout and stderr output
- Exit code
- Test summary with success/failure status

## Example Log Structure

```code-output
Test Execution Log - 2024-07-02 21:39:45.123456
Command: python -m pytest tests/test_example.py -v
Test File: tests/test_example.py
Working Directory: /Users/saifraja/Github/fiddler-chatbot
==================================================
Exit Code: 0
STDOUT:
========================= test session starts =========================
platform darwin -- Python 3.11.0, pytest-7.4.0
collected 3 items

tests/test_example.py::test_function PASSED [100%]

========================= 1 passed in 0.12s =========================

STDERR:

==================================================
Test Summary:
- Success: True
- Log file: logs/cursor_logs/test_run_2024-07-02_21-39-45.log
- Timestamp: 2024-07-02 21:39:45.123456
```

## Usage

The logging system is automatically triggered when:

- Cursor AI assistant runs any test command
- Test files are executed for verification
- Code changes need validation

Manual usage via the utility:

```python
from src.utils.test_logger import log_test_execution

log_file, success = log_test_execution(
    "python -m pytest tests/test_example.py -v",
    "tests/test_example.py"
)
```

## Verification Requirements

When AI reports test results, it must:

- Reference the specific log file created
- Include actual output snippets from the log
- Confirm real assertions were executed (not just print statements)
- Provide complete failure information when tests fail

## Red Flags - Hallucinated Tests

Watch out for these patterns that indicate fake tests:

- Tests with only `print("Test passed")` statements
- Functions that return success without actual verification
- Missing assertion statements or logical checks
- Tests that can't actually fail

## Maintenance

- Log files are automatically created in this directory
- Old log files can be archived or deleted as needed
- The directory structure is maintained by the test logger utility
- Sample format file shows expected log structure
