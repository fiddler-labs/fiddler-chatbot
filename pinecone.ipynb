{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039753da-c454-4cd3-adbc-983ace81bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4190b-0fad-4e95-9133-8da99e9794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41d186c-5e06-43d2-9360-4d04e5b65d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310e565f-dd3e-4ada-a0de-37930fb3b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.environ[\"PINECONE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e9cc72-5d14-47a4-adbb-86e65a64dfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbrock/opt/anaconda3/lib/python3.8/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'PINECONE_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-93b2a5a7fe88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpinecone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpinecone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PINECONE_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gcp-starter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpinecone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PINECONE_API_KEY'"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(api_key=os.environ[\"PINECONE_API_KEY\"], environment=\"gcp-starter\")\n",
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7b6b50-a2a1-4cc0-aa61-1416ecc87eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(\"fiddlerchat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cb9159-18ad-4073-8e70-97c49226be9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>package.py for R based models```python\\nimport...</td>\n",
       "      <td>[-0.009950872510671616, -0.011770655401051044,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---\\ntitle: \"Release 22.11 Notes\"\\nslug: \"rele...</td>\n",
       "      <td>[-0.005742393434047699, 0.001501509454101324, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---\\ntitle: \"Release 23.2 Notes\"\\nslug: \"relea...</td>\n",
       "      <td>[0.010167686268687248, -0.001216516480781138, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>---\\ntitle: \"Release 22.12 Notes\"\\nslug: \"rele...</td>\n",
       "      <td>[-0.010491670109331608, -0.0011956370435655117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>---\\ntitle: \"Release 23.1 Notes\"\\nslug: \"2023-...</td>\n",
       "      <td>[-0.00474295811727643, 0.0016190075548365712, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>---\\ntitle: \"Uploading a scikit-learn Model Ar...</td>\n",
       "      <td>[0.0031662925612181425, 0.018320860341191292, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>---\\ntitle: \"client.get_slice\"\\nslug: \"clientg...</td>\n",
       "      <td>[-0.0003570110129658133, -0.021801473572850227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Once you have added a model on the Fiddler pla...</td>\n",
       "      <td>[-0.022226542234420776, 0.011369146406650543, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Custom metrics is an upcoming feature and it i...</td>\n",
       "      <td>[-0.017716489732265472, -0.0035160724073648453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Re-uploading in Fiddler essentially means havi...</td>\n",
       "      <td>[-0.01760503277182579, 0.011651406064629555, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    package.py for R based models```python\\nimport...   \n",
       "1    ---\\ntitle: \"Release 22.11 Notes\"\\nslug: \"rele...   \n",
       "2    ---\\ntitle: \"Release 23.2 Notes\"\\nslug: \"relea...   \n",
       "3    ---\\ntitle: \"Release 22.12 Notes\"\\nslug: \"rele...   \n",
       "4    ---\\ntitle: \"Release 23.1 Notes\"\\nslug: \"2023-...   \n",
       "..                                                 ...   \n",
       "305  ---\\ntitle: \"Uploading a scikit-learn Model Ar...   \n",
       "306  ---\\ntitle: \"client.get_slice\"\\nslug: \"clientg...   \n",
       "307  Once you have added a model on the Fiddler pla...   \n",
       "308  Custom metrics is an upcoming feature and it i...   \n",
       "309  Re-uploading in Fiddler essentially means havi...   \n",
       "\n",
       "                                             embedding  \n",
       "0    [-0.009950872510671616, -0.011770655401051044,...  \n",
       "1    [-0.005742393434047699, 0.001501509454101324, ...  \n",
       "2    [0.010167686268687248, -0.001216516480781138, ...  \n",
       "3    [-0.010491670109331608, -0.0011956370435655117...  \n",
       "4    [-0.00474295811727643, 0.0016190075548365712, ...  \n",
       "..                                                 ...  \n",
       "305  [0.0031662925612181425, 0.018320860341191292, ...  \n",
       "306  [-0.0003570110129658133, -0.021801473572850227...  \n",
       "307  [-0.022226542234420776, 0.011369146406650543, ...  \n",
       "308  [-0.017716489732265472, -0.0035160724073648453...  \n",
       "309  [-0.01760503277182579, 0.011651406064629555, 0...  \n",
       "\n",
       "[310 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =\"documentation_data/chatbot_08_15_23_tk750.csv\"\n",
    "df = pd.read_csv(path)\n",
    "#df['embedding'] = df['embedding'].apply(ast.literal_eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a8bee7-a24f-4a6a-9992-88d99af14c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Blog title']==\"Fiddler Introduces End-to-End Workflow for Robust Generative AI\"][\"Content\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb3ebfc-d94d-4db5-a2b1-0edb72e43aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/Users/murtuzashergadwala/fiddlerchat/chatbot_08_15_23_tk750.csv\"\n",
    "# df = pd.read_csv(path)\n",
    "# df['embedding'] = df['embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "859b1684-0c14-4e52-8a4f-a0bc29b0b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.rename(columns={\"text\":\"metadata\", \"embedding\":\"values\", \"index\":\"id\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a9b6492-f129-49a9-a336-034f6fb506ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metadata'] = df['metadata'].apply(lambda x: {\"text\": x})\n",
    "df[\"id\"] = df[\"id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bee8ed7-3182-494b-80fa-ddf5c10253e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'text': 'AI has been in the limelight thanks ...</td>\n",
       "      <td>[-0.01476664375513792, -0.003117673797532916, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                           metadata  \\\n",
       "0  0  {'text': 'AI has been in the limelight thanks ...   \n",
       "\n",
       "                                              values  \n",
       "0  [-0.01476664375513792, -0.003117673797532916, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f644e1-b3ef-4ca1-97d9-43786ade91d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b79310555e471cb72dcd9da734079f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sending upsert requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert_from_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13907512-99ec-4b9d-ac68-a87536733a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0031,\n",
       " 'namespaces': {'': {'vector_count': 310}},\n",
       " 'total_vector_count': 310}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23685fb-4747-47df-a94d-2e67b01d7d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0031,\n",
       " 'namespaces': {'': {'vector_count': 310}},\n",
       " 'total_vector_count': 310}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418b656b-99a4-4826-874f-30ecc3def11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a9c4d49-55db-4fe5-8291-65794c2c65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"fiddlerchat\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf7b7ab-5362-4d8b-9b70-b9369e90cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what counterfactual analysis can I do on Fiddler?\"\n",
    "docs = docsearch.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea6f0792-775c-4ae2-a628-ad96609a9b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='slug: \"cv-monitoring\" _ID, \\'monitor\\']))\\n```\\n\\n*Please allow 3-5 minutes for monitoring data to populate the charts.*\\n  \\nThe following screen (without the annotation bubbles) will be available to you upon completion.\\n<table>\\n    <tr>\\n        <td>\\n            <img src=\"https://github.com/fiddler-labs/fiddler-examples/raw/main/quickstart/images/image_monitoring_drift.png\" />\\n        </td>\\n    </tr>\\n</table>\\n\\n\\n\\n---\\n\\n\\n**Questions?**  \\n  \\nCheck out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\\n\\nJoin our [community Slack](http://fiddler-community.slack.com/) to ask any questions!\\n\\nIf you\\'re still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we\\'ll get back to you shortly.\\n', metadata={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d0ead3e-417d-4e26-a4e5-037958141f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch.similarity_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b61e18ab-257a-4854-ac22-7d3891f6bdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Vector Monitoring\"\n",
      "slug: \"vector-monitoring-platform\"\n",
      "excerpt: \"\\\"Patent Pending\\\"\"\n",
      "hidden: false\n",
      "createdAt: \"2022-12-19T19:22:52.779Z\"\n",
      "updatedAt: \"2023-08-04T22:36:41.836Z\"\n",
      "---\n",
      "# Vector Monitoring for Unstructured Data\n",
      "\n",
      "While Fiddler calculates data drift at deployment time for numerical features that are stored in columns of the baseline dataset, many modern machine learning systems use input features that cannot be represented as a single number (e.g., text or image data). Such complex features are usually rather represented by high-dimensional vectors which are obtained by applying a vectorization method (e.g., text embeddings generated by NLP models). Furthermore, Fiddler users might be interested in monitoring a group of univariate features together and detecting data drift in multi-dimensional feature spaces.\n",
      "\n",
      "In order to address the above needs, Fiddler provides vector monitoring capability which involves enabling users to define custom features, and a novel method for monitoring data drift in multi-dimensional spaces.\n",
      "\n",
      "### Defining Custom Features\n",
      "\n",
      "Users can use the Fiddler client to define one or more custom features. Each custom feature is specified by a group of dataset columns that need to be monitored together as a vector. Once a list of custom features is defined and passed to Fiddler (the details of how to use the Fiddler client to define custom features are provided in the following.), Fiddler runs a clustering-based data drift detection algorithm for each custom feature and calculates a corresponding drift value between the baseline and the published events at the selected time period.\n",
      "\n",
      "```python pyth\n",
      "CF1 = fdl.CustomFeature.from_columns(['f1','f2','f3'], custom_name = 'vector1')\n",
      "CF2 = fdl.CustomFeature.from_columns(['f1','f2','f3'], n_clusters=5, custom_name = 'vector2')\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "### Passing Custom Features List to Model Info\n",
      "\n",
      "```python\n",
      "model_info = fdl.ModelInfo.from_dataset_info(\n",
      "    dataset_info=dataset_info,\n",
      "    dataset_id = DATASET_ID,\n",
      "    features = data_cols,\n",
      "    target='target',\n",
      "    outputs='predicted_score',\n",
      "    custom_features = [CF1,CF2]\n",
      ")\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "> ðŸ“˜ Quick Start for NLP Monitoring\n",
      "> \n",
      "> Check out our [Quick Start guide for NLP monitoring](https://docs.fiddler.ai/docs/simple-nlp-monitoring-quick-start) for a fully functional notebook example.\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9f16589-4c41-4976-970f-bc42dc1764de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='slug: \"cv-monitoring\" _ID, \\'monitor\\']))\\n```\\n\\n*Please allow 3-5 minutes for monitoring data to populate the charts.*\\n  \\nThe following screen (without the annotation bubbles) will be available to you upon completion.\\n<table>\\n    <tr>\\n        <td>\\n            <img src=\"https://github.com/fiddler-labs/fiddler-examples/raw/main/quickstart/images/image_monitoring_drift.png\" />\\n        </td>\\n    </tr>\\n</table>\\n\\n\\n\\n---\\n\\n\\n**Questions?**  \\n  \\nCheck out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\\n\\nJoin our [community Slack](http://fiddler-community.slack.com/) to ask any questions!\\n\\nIf you\\'re still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we\\'ll get back to you shortly.\\n', metadata={}),\n",
       " Document(page_content='---\\ntitle: \"Vector Monitoring\"\\nslug: \"vector-monitoring-platform\"\\nexcerpt: \"\\\\\"Patent Pending\\\\\"\"\\nhidden: false\\ncreatedAt: \"2022-12-19T19:22:52.779Z\"\\nupdatedAt: \"2023-08-04T22:36:41.836Z\"\\n---\\n# Vector Monitoring for Unstructured Data\\n\\nWhile Fiddler calculates data drift at deployment time for numerical features that are stored in columns of the baseline dataset, many modern machine learning systems use input features that cannot be represented as a single number (e.g., text or image data). Such complex features are usually rather represented by high-dimensional vectors which are obtained by applying a vectorization method (e.g., text embeddings generated by NLP models). Furthermore, Fiddler users might be interested in monitoring a group of univariate features together and detecting data drift in multi-dimensional feature spaces.\\n\\nIn order to address the above needs, Fiddler provides vector monitoring capability which involves enabling users to define custom features, and a novel method for monitoring data drift in multi-dimensional spaces.\\n\\n### Defining Custom Features\\n\\nUsers can use the Fiddler client to define one or more custom features. Each custom feature is specified by a group of dataset columns that need to be monitored together as a vector. Once a list of custom features is defined and passed to Fiddler (the details of how to use the Fiddler client to define custom features are provided in the following.), Fiddler runs a clustering-based data drift detection algorithm for each custom feature and calculates a corresponding drift value between the baseline and the published events at the selected time period.\\n\\n```python pyth\\nCF1 = fdl.CustomFeature.from_columns([\\'f1\\',\\'f2\\',\\'f3\\'], custom_name = \\'vector1\\')\\nCF2 = fdl.CustomFeature.from_columns([\\'f1\\',\\'f2\\',\\'f3\\'], n_clusters=5, custom_name = \\'vector2\\')\\n```\\n\\n\\n\\n### Passing Custom Features List to Model Info\\n\\n```python\\nmodel_info = fdl.ModelInfo.from_dataset_info(\\n    dataset_info=dataset_info,\\n    dataset_id = DATASET_ID,\\n    features = data_cols,\\n    target=\\'target\\',\\n    outputs=\\'predicted_score\\',\\n    custom_features = [CF1,CF2]\\n)\\n```\\n\\n\\n\\n> ðŸ“˜ Quick Start for NLP Monitoring\\n> \\n> Check out our [Quick Start guide for NLP monitoring](https://docs.fiddler.ai/docs/simple-nlp-monitoring-quick-start) for a fully functional notebook example.', metadata={}),\n",
       " Document(page_content='---\\ntitle: \"CV Monitoring\"\\nslug: \"cv-monitoring\"\\nexcerpt: \"Quickstart Notebook\"\\nhidden: false\\ncreatedAt: \"2023-01-31T19:44:34.862Z\"\\nupdatedAt: \"2023-03-07T21:39:35.954Z\"\\n---\\nThis guide will walk you through the basic steps required to use Fiddler for monitoring computer vision (CV) models. In this notebook we demonstrate how to detect drift in image data using model embeddings using Fiddler\\'s unique Vector Monitoring approach.\\n\\nClick the following link to get started using Google Colab:\\n\\n<div class=\"colab-box\">\\n    <a href=\"https://colab.research.google.com/github/fiddler-labs/fiddler-examples/blob/main/quickstart/Fiddler_Quickstart_Image_Monitoring.ipynb\" target=\"_blank\">\\n        <div>\\n            Open in Google Colab â†’\\n        </div>\\n    </a>\\n    <div>\\n            <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" />\\n    </div>\\n</div># Monitoring Image data using Fiddler Vector Monotoring\\n\\nIn this notebook we present the steps for monitoring images. Fiddler employs a vector-based monitoring approach that can be used to monitor data drift in high-dimensional data such as NLP embeddings, images, video etc. In this notebook we demonstrate how to detect drift in image data using model embeddings.\\n\\nFiddler is the pioneer in enterprise Model Performance Management (MPM), offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve ML deployments at enterprise scale**. \\nObtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue.\\n\\n---\\n\\nYou can experience Fiddler\\'s Image monitoring ***in minutes*** by following these quick steps:\\n\\n1. Connect to Fiddler\\n2. Load and generate embeddings for CIFAR-10 dataset\\n3. Upload the vectorized baseline dataset\\n4. Add metadata about your model \\n5. Inject data drift and publish production events\\n6. Get insights\\n\\n## Imports\\n\\n\\n```python\\n!pip install torch==2.0.0\\n!pip install torchvision==0.15.1\\n!pip install -q fiddler-client\\n```\\n\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\nimport random\\nimport time\\nimport torch\\nimport torch.nn as nn\\nimport torchvision.transforms as transforms\\nfrom torchvision.models import resnet18, ResNet18_Weights\\nimport torchvision\\nimport requests\\n\\nimport fiddler as fdl\\nprint(f\"Running Fiddler client version {fdl.__version__}\")\\n```\\n\\n# 1. Connect to Fiddler\\n\\nBefore you can add information about your model with Fiddler, you\\'ll need to connect using our API client.\\n\\n---\\n\\n**We need a few pieces of information to get started.**\\n1. The URL you\\'re using to connect to Fiddler\\n2. Your organization ID\\n3. Your authorization token\\n\\nThe latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page.\\n\\n\\n```python\\nURL = \\'\\'  # Make sure to include the full URL (including https://).\\nORG_ID = \\'\\'\\nAUTH_TOKEN = \\'\\'\\n```\\n\\nNow just run the following code block to connect to the Fiddler API!\\n\\n\\n```python\\nclient = fdl.FiddlerApi(\\n    url=URL,\\n    org_id=ORG_ID,\\n', metadata={}),\n",
       " Document(page_content='slug: \"data-drift\" e-Monitor_DriftAnaly.png \"Monitor_DriftAnaly.png\")\\n\\n## Why is it being tracked?\\n\\n- Data drift is a great proxy metric for **performance decline**, especially if there is delay in getting labels for production events. (e.g. In a credit lending use case, an actual default may happen after months or years.)\\n- Monitoring data drift also helps you stay informed about **distributional shifts in the data for features of interest**, which could have business implications even if there is no decline in model performance.\\n\\n## What do I do next with this information?\\n\\n- High drift can occur as a result of _data integrity issues_ (bugs in the data pipeline), or as a result of _an actual change in the distribution of data_ due to external factors (e.g. a dip in income due to COVID). The former is more in our control to solve directly. The latter may not be solvable directly, but can serve as an indicator that further investigation (and possible retraining) may be needed.\\n- You can drill down deeper into the data by examining it in the Analyze tab. \\n\\nThe image below shows how to open the Analyze view for a specific feature and time range identified in the Data Drift page.\\n\\n![](https://files.readme.io/8a699e1-Monitor_DDrift_Analyze.png \"Monitor_DDrift_Analyze.png\")\\n\\nThis will bring you to the Analyze tab, where you can then use SQL to slice and dice the data.  You can then apply visualizations upon these slices to analyze the modelâ€™s behavior.\\n\\n![](https://files.readme.io/25eca03-Monitor_Analyze.png \"Monitor_Analyze.png\")\\n\\n**Reference**\\n\\n- See our article on [_The Rise of MLOps Monitoring_](https://www.fiddler.ai/blog/the-rise-of-mlops-monitoring)\\n\\n[^1]\\\\: _Join our [community Slack](http://fiddler-community.slack.com/) to ask any questions_\\n\\n\\n\\n[block:html]\\n{\\n  \"html\": \"<div class=\\\\\"fiddler-cta\\\\\">\\\\n<a class=\\\\\"fiddler-cta-link\\\\\" href=\\\\\"https://www.fiddler.ai/trial?utm_source=fiddler_docs&utm_medium=referral\\\\\"><img src=\\\\\"https://files.readme.io/af83f1a-fiddler-docs-cta-trial.png\\\\\" alt=\\\\\"Fiddler Free Trial\\\\\"></a>\\\\n</div>\"\\n}\\n[/block]', metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffad3951-a255-444a-83e7-482a6f3548ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a tool called Fiddler Chatbot \n",
    "and your purpose is to use the below documentation from the company Fiddler to answer the subsequent documentation questions.\n",
    "Also, if possible, give me the reference URLs according to the following instructions. \n",
    "The way to create the URLs is: add \"https://docs.fiddler.ai/docs/\" before the \"slug\" value of the document. \n",
    "For any URL references that start with \"doc:\" or \"ref:\" use its value to create a URL by adding \"https://docs.fiddler.ai/docs/\" before that value.\n",
    "Do not use page titles to create urls. Note that if a user asks about uploading events, it means the same as publishing events. \n",
    "If the answer cannot be found in the documentation, write \"I could not find an answer.\"\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e04de-ce75-4851-9681-cf0cb758ac4e",
   "metadata": {},
   "source": [
    "### chain with 10 returned docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf621e3e-84f3-41e4-970a-f7535f0924da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=docsearch.as_retriever(search_kwargs={'k':10}), chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca254bc4-fae0-41ac-a408-72a62320c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To upload model artifacts in Fiddler, you can use the `client.add_model_artifact` function. This function allows you to upload your model artifact to Fiddler. You can find more information on uploading model artifacts in the [Uploading model artifacts](https://docs.fiddler.ai/docs/uploading-model-artifacts) documentation.\n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/uploading-model-artifacts](https://docs.fiddler.ai/docs/uploading-model-artifacts)\n"
     ]
    }
   ],
   "source": [
    "question = \"What API can i use to upload model artifacts?\"\n",
    "result  = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8958678b-165d-477d-9f42-80b5b5ed3cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiddler offers a Python Client that allows users to connect to Fiddler directly from a Python notebook or automated pipeline. Each client function is documented with a description, usage information, and code examples. Additionally, Fiddler offers an integration with Datadog, allowing customers to bring their AI Observability metrics from Fiddler into their centralized Datadog dashboards. The integration enables users to centralize their monitoring of ML models and the applications that utilize them within one unified platform. \n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/about-the-fiddler-client](https://docs.fiddler.ai/docs/about-the-fiddler-client)\n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/datadog-integration](https://docs.fiddler.ai/docs/datadog-integration)\n"
     ]
    }
   ],
   "source": [
    "question = \"What does Fiddler offer?\"\n",
    "result  = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cc5428d-b6a3-466a-892f-5ee51b6c8c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiddler platform capabilities include AI Observability, Model Performance Management, Explainability, and Monitoring. These capabilities allow users to monitor, explain, analyze, and improve ML models, generative AI models, and AI applications. For more information, you can refer to the [Welcome to Fiddler's Documentation](https://docs.fiddler.ai/docs/welcome) document.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are Fiddler platform capabilities?\"\n",
    "result  = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ead0ca-fa0f-4570-b3b7-9abc0680839b",
   "metadata": {},
   "source": [
    "### generic chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e2107c-7d5a-4dcb-bf24-e8f1d8c3a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=docsearch.as_retriever(), chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c8523-7364-4305-9d85-03dcfe465b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What API can i use to upload model artifacts?\"\n",
    "result  = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f55cc272-79a1-4ecc-a0bc-b4f0d38c7c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the `client.add_model_artifact` API to upload model artifacts. \n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/clientadd_model_artifact](https://docs.fiddler.ai/docs/clientadd_model_artifact)\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3110230-1936-4f13-ab7c-936de5c5efb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What API can i use to upload model artifacts?',\n",
       " 'result': 'You can use the `client.add_model_artifact` API to upload model artifacts. \\n\\nReference URL: [https://docs.fiddler.ai/docs/clientadd_model_artifact](https://docs.fiddler.ai/docs/clientadd_model_artifact)'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e725f31-34b1-4585-95d5-ee6ca73ed2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What does Fiddler offer?\"\n",
    "result  = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8351f728-477c-4516-b8ba-bf40d3ec33db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiddler offers a Python Client that allows users to connect to Fiddler directly from a Python notebook or automated pipeline. This client contains many useful methods for sending and receiving data to and from the Fiddler platform. Additionally, Fiddler offers an integration with Datadog, allowing customers to bring their AI Observability metrics from Fiddler into their centralized Datadog dashboards. The integration enables users to centralize their monitoring of ML models and the applications that utilize them within one unified platform. \n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/about-the-fiddler-client](https://docs.fiddler.ai/docs/about-the-fiddler-client)\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0b8a9-dbf9-48ce-8227-656b8af4d2f7",
   "metadata": {},
   "source": [
    "## chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74b6311c-01d4-4e95-a5bf-3f47ab5f7933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "chat([HumanMessage(content=\"Translate this sentence from English to French: I love programming.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bde23f50-e323-40f4-99de-36f35d5a73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\",return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "551f05db-79e6-4992-9986-1d0ef7aa3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4df4f34-7ac3-4053-ab16-27c26953d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=docsearch.as_retriever(search_kwargs={'k':5}), memory=memory, max_tokens_limit=4000,combine_docs_chain_kwargs ={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b9585b0-6287-49b6-93a0-b8e3aad0190e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are model artifacts?',\n",
       " 'chat_history': [SystemMessage(content='The human asks how to write a `package.py` for R models. The AI provides an example script that defines a `Model` class to load and use an R model using the `rpy2` library. The `load` method loads the R model from a specified path, and the `predict` method performs classification on input data using the loaded model. The `get_model` function returns an instance of the `Model` class. The AI suggests customizing the `package.py` script based on specific R model and requirements. The human asks what API can be used to upload R models. The AI suggests using the `upload_model_package` API from the Fiddler Python API client and provides an example of how to use it. The AI explains that the `upload_model_package` API requires the `artifact_path` parameter, which is the path to the directory containing the R model files, the `project_id` parameter, which is the ID of the project to upload the model to, and the `model_id` parameter, which is the ID to assign to the model. The AI also provides a reference URL for more information.', additional_kwargs={})],\n",
       " 'answer': 'Model artifacts refer to the files and resources that are associated with a machine learning model. These artifacts include the model file, which is a serialized representation of the model, and the package.py wrapper script, which provides instructions on how to interact with the model. Other optional artifacts can also be included, such as a model.yaml configuration file and serialized preprocessing objects. These artifacts are used for monitoring, explainability, and other capabilities in Fiddler. \\n\\nReference URL: [https://docs.fiddler.ai/docs/artifacts-and-surrogates](https://docs.fiddler.ai/docs/artifacts-and-surrogates)'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"What are model artifacts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa234b9a-bafc-4a2e-84d1-a22b69311424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What API can i use to upload them?',\n",
       " 'chat_history': [SystemMessage(content='The human asks how to write a `package.py` for R models. The AI provides an example script that defines a `Model` class to load and use an R model using the `rpy2` library. The `load` method loads the R model from a specified path, and the `predict` method performs classification on input data using the loaded model. The `get_model` function returns an instance of the `Model` class. The AI suggests customizing the `package.py` script based on specific R model and requirements.', additional_kwargs={})],\n",
       " 'answer': 'To upload R models, you can use the `upload_model_package` API from the Fiddler Python API client. Here is an example of how to use it:\\n\\n```python\\nclient.upload_model_package(artifact_path=model_dir, project_id=project_id, model_id=model_id)\\n```\\n\\nYou need to provide the `artifact_path` parameter, which is the path to the directory containing the R model files. In this case, it is `model_dir`. The `project_id` parameter is the ID of the project you want to upload the model to, and the `model_id` parameter is the ID you want to assign to the model.\\n\\nReference URL: [https://docs.fiddler.ai/docs/uploading-models](https://docs.fiddler.ai/docs/uploading-models)'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"What API can i use to upload them?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e7d4bd6-4902-42cd-81da-96208938baf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can i write a package.py for R models?',\n",
       " 'chat_history': [SystemMessage(content='', additional_kwargs={})],\n",
       " 'answer': 'To write a `package.py` for R models, you can follow the example below:\\n\\n```python\\nfrom pathlib import Path\\nimport numpy as np\\nimport pandas as pd\\nimport rpy2.robjects as robjects\\nfrom rpy2.robjects import numpy2ri, pandas2ri\\nfrom rpy2.robjects.packages import importr\\n\\npandas2ri.activate()\\nnumpy2ri.activate()\\nr = robjects.r\\n\\nclass Model:\\n    \"\"\"\\n    R Model Loader\\n\\n    Attributes\\n    ----------\\n    model : R object\\n    \"\"\"\\n\\n    def __init__(self):\\n        self.model = None\\n\\n    def load(self, path):\\n        \"\"\"\\n        load the model at `path`\\n        \"\"\"\\n        model_rds_path = f\\'{path}.rds\\'\\n\\n        self.model = r.readRDS(model_rds_path)\\n        \\n        _ = [importr(dep.strip()) for dep in [\\'randomForest\\'] if dep.strip() != \\'\\']\\n\\n        return self\\n\\n    def predict(self, input_df):\\n        \"\"\"\\n        Perform classification on samples in X.\\n\\n        Parameters\\n        ----------\\n        input_df : pandas dataframe, shape (n_samples, n_features)\\n        Returns\\n        -------\\n        pred : array, shape (n_samples)\\n        \"\"\"\\n\\n        if self.model is None:\\n            raise Exception(\\'There is no Model\\')\\n\\n        pred = r.predict(self.model, [input_df], type=\\'prob\\')\\n        df = pd.DataFrame(np.array(pred), columns=[\\'proba_setosa\\', \\'proba_versicolor\\', \\'proba_virginica\\'])\\n\\n        return df\\n\\nMODEL_PATH = \\'iris\\'\\nPACKAGE_PATH = Path(__file__).parent\\n\\ndef get_model():\\n    return Model().load(str(PACKAGE_PATH / MODEL_PATH))\\n```\\n\\nIn this example, we define a `Model` class that loads an R model using the `rpy2` library. The `load` method loads the R model from the specified path, and the `predict` method performs classification on input data using the loaded model. The `get_model` function returns an instance of the `Model` class.\\n\\nYou can customize this `package.py` script based on your specific R model and requirements.\\n\\nReference URL: [https://docs.fiddler.ai/docs/model-task-examples](https://docs.fiddler.ai/docs/model-task-examples)'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"How can i write a package.py for R models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03000498-90ec-4d04-979d-f722651865cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who are you?',\n",
       " 'chat_history': [SystemMessage(content='The human asks how to write a `package.py` for R models. The AI provides an example script that defines a `Model` class to load and use an R model using the `rpy2` library. The `load` method loads the R model from a specified path, and the `predict` method performs classification on input data using the loaded model. The `get_model` function returns an instance of the `Model` class. The AI suggests customizing the `package.py` script based on specific R model and requirements. The human asks what API can be used to upload R models. The AI suggests using the `upload_model_package` API from the Fiddler Python API client and provides an example of how to use it. The AI explains that the `upload_model_package` API requires the `artifact_path` parameter, which is the path to the directory containing the R model files, the `project_id` parameter, which is the ID of the project to upload the model to, and the `model_id` parameter, which is the ID to assign to the model. The AI also provides a reference URL for more information. The human asks what model artifacts are. The AI explains that model artifacts refer to the files and resources associated with a machine learning model, including the model file, the `package.py` wrapper script, and optional artifacts like a `model.yaml` configuration file and serialized preprocessing objects. These artifacts are used for monitoring, explainability, and other capabilities in Fiddler.\\n\\nNew lines of conversation:\\nHuman: Can you explain more about the `model.yaml` configuration file?\\nAI: The `model.yaml` configuration file is an optional artifact that can be included with the model artifacts. It provides additional information about the model, such as its name, description, version, and any dependencies it may have. This file helps in organizing and managing models within Fiddler, and it can be used for versioning and tracking changes to the model. The `model.yaml` file follows a YAML format, which is a human-readable data serialization format. It can be customized based on the specific requirements of the model and the project.', additional_kwargs={})],\n",
       " 'answer': 'I am Fiddler Chatbot, a tool designed to provide information and answer questions based on the documentation from the company Fiddler.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ceefee50-8c55-4772-89b9-a080c50fa77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryMemory(human_prefix='Human', ai_prefix='AI', llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), prompt=PromptTemplate(input_variables=['summary', 'new_lines'], output_parser=None, partial_variables={}, template='Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:', template_format='f-string', validate_template=True), summary_message_cls=<class 'langchain.schema.messages.SystemMessage'>, chat_memory=ChatMessageHistory(messages=[HumanMessage(content='How can i write a package.py for R models?', additional_kwargs={}, example=False), AIMessage(content='To write a `package.py` for R models, you can follow the example below:\\n\\n```python\\nfrom pathlib import Path\\nimport numpy as np\\nimport pandas as pd\\nimport rpy2.robjects as robjects\\nfrom rpy2.robjects import numpy2ri, pandas2ri\\nfrom rpy2.robjects.packages import importr\\n\\npandas2ri.activate()\\nnumpy2ri.activate()\\nr = robjects.r\\n\\nclass Model:\\n    \"\"\"\\n    R Model Loader\\n\\n    Attributes\\n    ----------\\n    model : R object\\n    \"\"\"\\n\\n    def __init__(self):\\n        self.model = None\\n\\n    def load(self, path):\\n        \"\"\"\\n        load the model at `path`\\n        \"\"\"\\n        model_rds_path = f\\'{path}.rds\\'\\n\\n        self.model = r.readRDS(model_rds_path)\\n        \\n        _ = [importr(dep.strip()) for dep in [\\'randomForest\\'] if dep.strip() != \\'\\']\\n\\n        return self\\n\\n    def predict(self, input_df):\\n        \"\"\"\\n        Perform classification on samples in X.\\n\\n        Parameters\\n        ----------\\n        input_df : pandas dataframe, shape (n_samples, n_features)\\n        Returns\\n        -------\\n        pred : array, shape (n_samples)\\n        \"\"\"\\n\\n        if self.model is None:\\n            raise Exception(\\'There is no Model\\')\\n\\n        pred = r.predict(self.model, [input_df], type=\\'prob\\')\\n        df = pd.DataFrame(np.array(pred), columns=[\\'proba_setosa\\', \\'proba_versicolor\\', \\'proba_virginica\\'])\\n\\n        return df\\n\\nMODEL_PATH = \\'iris\\'\\nPACKAGE_PATH = Path(__file__).parent\\n\\ndef get_model():\\n    return Model().load(str(PACKAGE_PATH / MODEL_PATH))\\n```\\n\\nIn this example, we define a `Model` class that loads an R model using the `rpy2` library. The `load` method loads the R model from the specified path, and the `predict` method performs classification on input data using the loaded model. The `get_model` function returns an instance of the `Model` class.\\n\\nYou can customize this `package.py` script based on your specific R model and requirements.\\n\\nReference URL: [https://docs.fiddler.ai/docs/model-task-examples](https://docs.fiddler.ai/docs/model-task-examples)', additional_kwargs={}, example=False), HumanMessage(content='What API can i use to upload them?', additional_kwargs={}, example=False), AIMessage(content='To upload R models, you can use the `upload_model_package` API from the Fiddler Python API client. Here is an example of how to use it:\\n\\n```python\\nclient.upload_model_package(artifact_path=model_dir, project_id=project_id, model_id=model_id)\\n```\\n\\nYou need to provide the `artifact_path` parameter, which is the path to the directory containing the R model files. In this case, it is `model_dir`. The `project_id` parameter is the ID of the project you want to upload the model to, and the `model_id` parameter is the ID you want to assign to the model.\\n\\nReference URL: [https://docs.fiddler.ai/docs/uploading-models](https://docs.fiddler.ai/docs/uploading-models)', additional_kwargs={}, example=False), HumanMessage(content='What are model artifacts?', additional_kwargs={}, example=False), AIMessage(content='Model artifacts refer to the files and resources that are associated with a machine learning model. These artifacts include the model file, which is a serialized representation of the model, and the package.py wrapper script, which provides instructions on how to interact with the model. Other optional artifacts can also be included, such as a model.yaml configuration file and serialized preprocessing objects. These artifacts are used for monitoring, explainability, and other capabilities in Fiddler. \\n\\nReference URL: [https://docs.fiddler.ai/docs/artifacts-and-surrogates](https://docs.fiddler.ai/docs/artifacts-and-surrogates)', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, buffer='The human asks how to write a `package.py` for R models. The AI provides an example script that defines a `Model` class to load and use an R model using the `rpy2` library. The `load` method loads the R model from a specified path, and the `predict` method performs classification on input data using the loaded model. The `get_model` function returns an instance of the `Model` class. The AI suggests customizing the `package.py` script based on specific R model and requirements. The human asks what API can be used to upload R models. The AI suggests using the `upload_model_package` API from the Fiddler Python API client and provides an example of how to use it. The AI explains that the `upload_model_package` API requires the `artifact_path` parameter, which is the path to the directory containing the R model files, the `project_id` parameter, which is the ID of the project to upload the model to, and the `model_id` parameter, which is the ID to assign to the model. The AI also provides a reference URL for more information. The human asks what model artifacts are. The AI explains that model artifacts refer to the files and resources associated with a machine learning model, including the model file, the `package.py` wrapper script, and optional artifacts like a `model.yaml` configuration file and serialized preprocessing objects. These artifacts are used for monitoring, explainability, and other capabilities in Fiddler.\\n\\nNew lines of conversation:\\nHuman: Can you explain more about the `model.yaml` configuration file?\\nAI: The `model.yaml` configuration file is an optional artifact that can be included with the model artifacts. It provides additional information about the model, such as its name, description, version, and any dependencies it may have. This file helps in organizing and managing models within Fiddler, and it can be used for versioning and tracking changes to the model. The `model.yaml` file follows a YAML format, which is a human-readable data serialization format. It can be customized based on the specific requirements of the model and the project.', memory_key='chat_history')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce98210-f0cc-4f07-b915-891c5816da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import AsyncIteratorCallbackHandlerfrom langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\",return_messages=True)\n",
    "\n",
    "callback = StreamingStdOutCallbackHandler()\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", streaming=True, callbacks=[callback], temperature=0) \n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=docsearch.as_retriever(search_kwargs={'k':5}), memory=memory, max_tokens_limit=4000,combine_docs_chain_kwargs ={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5ba49-51e1-4544-a09f-f27f6f628958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a45fad2d-9ef9-4f78-91e0-7b4042fdc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def generate_response(question):\n",
    "    \n",
    "    task = asyncio.create_task(\n",
    "        qa.acall(question),\n",
    "    )\n",
    "    async for token in callback.aiter():\n",
    "        yield token\n",
    "    await task\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e5cd29a-c33d-4d18-a354-c1ff87f164fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_response(\"what is model monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e66de285-3b7d-448b-92f5-efba93a56016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object generate_response at 0x7ff523cabb80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "727fe1a3-6658-4488-a7dd-48ca1737115e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What\n",
      " is\n",
      " model\n",
      " monitoring\n",
      "?\n",
      "The human asks what model monitoring is. The AI explains that model monitoring is the process of continuously tracking and analyzing the performance and behavior of a machine learning model in production. It involves monitoring various aspects of the model, such as data integrity, feature drift, and overall model performance. The goal of model monitoring is to identify any issues or anomalies and take appropriate actions to mitigate them, such as setting up alerts, investigating the root cause, and retraining the model with new data. Model monitoring helps ensure that the model is performing as expected and delivering accurate and reliable predictions."
     ]
    }
   ],
   "source": [
    "async for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92ec1915-8723-4e94-ba58-8bcd72d93734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object generate_response at 0x7ff523cabb80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32b3767a-e305-4463-9d76-abc42496c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you provide an example of a `package.py` script?Sure! Here is an example of a `package.py` script for a binary classification model:\n",
      "\n",
      "```python\n",
      "import pickle\n",
      "from pathlib import Path\n",
      "import pandas as pd\n",
      "\n",
      "PACKAGE_PATH = Path(__file__).parent\n",
      "\n",
      "OUTPUT_COLUMN = ['probability_over_50k']\n",
      "\n",
      "class MyModel:\n",
      "\n",
      "    def __init__(self):\n",
      "        \n",
      "        # Load the model\n",
      "        with open(PACKAGE_PATH / 'model.pkl', 'rb') as pkl_file:\n",
      "            self.model = pickle.load(pkl_file)\n",
      "\n",
      "    def predict(self, input_df):\n",
      "        \n",
      "        # Store predictions in a DataFrame\n",
      "        return pd.DataFrame(self.model.predict_proba(input_df)[:, 1], columns=OUTPUT_COLUMN)\n",
      "\n",
      "def get_model():\n",
      "    return MyModel()\n",
      "```\n",
      "\n",
      "In this example, the script loads a binary classification model from a `model.pkl` file and defines a `MyModel` class with a `predict` method that takes an input DataFrame and returns a DataFrame of predictions. The predictions are stored in a column called `probability_over_50k`.\n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/binary-classification-1](https://docs.fiddler.ai/docs/binary-classification-1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Give an example of a package.py',\n",
       " 'chat_history': [SystemMessage(content='The human asks how to write a `package.py` for R models. The AI provides an example script that defines a `Model` class to load and use an R model using the `rpy2` library. The `load` method loads the R model from a specified path, and the `predict` method performs classification on input data using the loaded model. The `get_model` function returns an instance of the `Model` class. The AI suggests customizing the `package.py` script based on specific R model and requirements. The human asks what API can be used to upload R models. The AI suggests using the `upload_model_package` API from the Fiddler Python API client and provides an example of how to use it. The AI explains that the `upload_model_package` API requires the `artifact_path` parameter, which is the path to the directory containing the R model files, the `project_id` parameter, which is the ID of the project to upload the model to, and the `model_id` parameter, which is the ID to assign to the model. The AI also provides a reference URL for more information. The human asks what model artifacts are. The AI explains that model artifacts refer to the files and resources associated with a machine learning model, including the model file, the `package.py` wrapper script, and optional artifacts like a `model.yaml` configuration file and serialized preprocessing objects. These artifacts are used for monitoring, explainability, and other capabilities in Fiddler. The human asks for more information about the `model.yaml` configuration file. The AI explains that the `model.yaml` configuration file is an optional artifact that provides additional information about the model, such as its name, description, version, and dependencies. It helps in organizing and managing models within Fiddler and can be used for versioning and tracking changes. The `model.yaml` file follows a YAML format and can be customized based on the model and project requirements. The human asks who the AI is. The AI introduces itself as Fiddler Chatbot, a tool designed to provide information and answer questions based on the documentation from the company Fiddler.', additional_kwargs={})],\n",
       " 'answer': \"Sure! Here is an example of a `package.py` script for a binary classification model:\\n\\n```python\\nimport pickle\\nfrom pathlib import Path\\nimport pandas as pd\\n\\nPACKAGE_PATH = Path(__file__).parent\\n\\nOUTPUT_COLUMN = ['probability_over_50k']\\n\\nclass MyModel:\\n\\n    def __init__(self):\\n        \\n        # Load the model\\n        with open(PACKAGE_PATH / 'model.pkl', 'rb') as pkl_file:\\n            self.model = pickle.load(pkl_file)\\n\\n    def predict(self, input_df):\\n        \\n        # Store predictions in a DataFrame\\n        return pd.DataFrame(self.model.predict_proba(input_df)[:, 1], columns=OUTPUT_COLUMN)\\n\\ndef get_model():\\n    return MyModel()\\n```\\n\\nIn this example, the script loads a binary classification model from a `model.pkl` file and defines a `MyModel` class with a `predict` method that takes an input DataFrame and returns a DataFrame of predictions. The predictions are stored in a column called `probability_over_50k`.\\n\\nReference URL: [https://docs.fiddler.ai/docs/binary-classification-1](https://docs.fiddler.ai/docs/binary-classification-1)\"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"Give an example of a package.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79cb5d22-9715-4394-b096-e80ab18cee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "\n",
    "callback = StreamingStdOutCallbackHandler()\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", streaming=True, callbacks=[callback], temperature=0) \n",
    "non_stream_llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "question_generator = LLMChain(llm=non_stream_llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_CHAIN_PROMPT)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm ,memory_key=\"chat_history\",return_messages=True, output_key=\"answer\")\n",
    "\n",
    "qa = ConversationalRetrievalChain(combine_docs_chain=doc_chain, question_generator=question_generator, retriever=docsearch.as_retriever(search_kwargs={'k':5}), memory=memory, max_tokens_limit=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7802a6ce-db78-43c0-b47c-9a42ef52e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "958aee24-1c09-4f4c-a6e3-ef0151dfc5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is an example of a `package.py` script for a binary classification model:\n",
      "\n",
      "```python\n",
      "import pickle\n",
      "from pathlib import Path\n",
      "import pandas as pd\n",
      "\n",
      "PACKAGE_PATH = Path(__file__).parent\n",
      "\n",
      "OUTPUT_COLUMN = ['probability_over_50k']\n",
      "\n",
      "class MyModel:\n",
      "\n",
      "    def __init__(self):\n",
      "        \n",
      "        # Load the model\n",
      "        with open(PACKAGE_PATH / 'model.pkl', 'rb') as pkl_file:\n",
      "            self.model = pickle.load(pkl_file)\n",
      "\n",
      "    def predict(self, input_df):\n",
      "        \n",
      "        # Store predictions in a DataFrame\n",
      "        return pd.DataFrame(self.model.predict_proba(input_df)[:, 1], columns=OUTPUT_COLUMN)\n",
      "\n",
      "def get_model():\n",
      "    return MyModel()\n",
      "```\n",
      "\n",
      "In this example, the `package.py` script defines a class `MyModel` that loads a binary classification model from a `model.pkl` file. The `predict` method takes an input DataFrame `input_df` and returns a DataFrame with the predicted probabilities of the positive class, using the column name `probability_over_50k`. The `get_model` function returns an instance of the `MyModel` class.\n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/binary-classification-1](https://docs.fiddler.ai/docs/binary-classification-1)The human asks the AI to give an example of a `package.py` script. The AI provides an example of a `package.py` script for a binary classification model. The script defines a class `MyModel` that loads a binary classification model from a `model.pkl` file. The `predict` method takes an input DataFrame and returns a DataFrame with the predicted probabilities of the positive class. The `get_model` function returns an instance of the `MyModel` class."
     ]
    }
   ],
   "source": [
    "result = qa(\"Give an example of a package.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdc1204a-8e90-418f-b8bf-c5f49923d45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Give an example of a package.py',\n",
       " 'chat_history': [SystemMessage(content='', additional_kwargs={})],\n",
       " 'answer': \"Sure! Here is an example of a `package.py` script for a binary classification model:\\n\\n```python\\nimport pickle\\nfrom pathlib import Path\\nimport pandas as pd\\n\\nPACKAGE_PATH = Path(__file__).parent\\n\\nOUTPUT_COLUMN = ['probability_over_50k']\\n\\nclass MyModel:\\n\\n    def __init__(self):\\n        \\n        # Load the model\\n        with open(PACKAGE_PATH / 'model.pkl', 'rb') as pkl_file:\\n            self.model = pickle.load(pkl_file)\\n\\n    def predict(self, input_df):\\n        \\n        # Store predictions in a DataFrame\\n        return pd.DataFrame(self.model.predict_proba(input_df)[:, 1], columns=OUTPUT_COLUMN)\\n\\ndef get_model():\\n    return MyModel()\\n```\\n\\nIn this example, the `package.py` script defines a class `MyModel` that loads a binary classification model from a `model.pkl` file. The `predict` method takes an input DataFrame `input_df` and returns a DataFrame with the predicted probabilities of the positive class, using the column name `probability_over_50k`. The `get_model` function returns an instance of the `MyModel` class.\\n\\nReference URL: [https://docs.fiddler.ai/docs/binary-classification-1](https://docs.fiddler.ai/docs/binary-classification-1)\"}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3102ec41-1e76-4d62-b275-3c0dd009c3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryMemory(human_prefix='Human', ai_prefix='AI', llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), prompt=PromptTemplate(input_variables=['summary', 'new_lines'], output_parser=None, partial_variables={}, template='Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:', template_format='f-string', validate_template=True), summary_message_cls=<class 'langchain.schema.messages.SystemMessage'>, chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Give an example of a package.py', additional_kwargs={}, example=False), AIMessage(content=\"Sure! Here is an example of a `package.py` script for a binary classification model:\\n\\n```python\\nimport pickle\\nfrom pathlib import Path\\nimport pandas as pd\\n\\nPACKAGE_PATH = Path(__file__).parent\\n\\nOUTPUT_COLUMN = ['probability_over_50k']\\n\\nclass MyModel:\\n\\n    def __init__(self):\\n        \\n        # Load the model\\n        with open(PACKAGE_PATH / 'model.pkl', 'rb') as pkl_file:\\n            self.model = pickle.load(pkl_file)\\n\\n    def predict(self, input_df):\\n        \\n        # Store predictions in a DataFrame\\n        return pd.DataFrame(self.model.predict_proba(input_df)[:, 1], columns=OUTPUT_COLUMN)\\n\\ndef get_model():\\n    return MyModel()\\n```\\n\\nIn this example, the `package.py` script defines a class `MyModel` that loads a binary classification model from a `model.pkl` file. The `predict` method takes an input DataFrame `input_df` and returns a DataFrame with the predicted probabilities of the positive class, using the `predict_proba` method of the model. The predicted probabilities are stored in a column called `probability_over_50k`.\\n\\nReference URL: [https://docs.fiddler.ai/docs/binary-classification-1](https://docs.fiddler.ai/docs/binary-classification-1)\", additional_kwargs={}, example=False)]), output_key='answer', input_key=None, return_messages=True, buffer='The human asks for an example of a `package.py` script. The AI provides an example of a `package.py` script for a binary classification model. The script defines a class `MyModel` that loads a binary classification model from a `model.pkl` file. The `predict` method takes an input DataFrame `input_df` and returns a DataFrame with the predicted probabilities of the positive class. The predicted probabilities are stored in a column called `probability_over_50k`.', memory_key='chat_history')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd59a9c8-ad61-4f4c-9c50-5b4a7ceafcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "template = \"\"\"You are a tool called Fiddler Chatbot \n",
    "and your purpose is to use the below documentation from the company Fiddler to answer the subsequent documentation questions.\n",
    "Also, if possible, give me the reference URLs according to the following instructions. \n",
    "The way to create the URLs is: add \"https://docs.fiddler.ai/docs/\" before the \"slug\" value of the document. \n",
    "For any URL references that start with \"doc:\" or \"ref:\" use its value to create a URL by adding \"https://docs.fiddler.ai/docs/\" before that value.\n",
    "Do not use page titles to create urls. Note that if a user asks about uploading events, it means the same as publishing events. \n",
    "If the answer cannot be found in the documentation, write \"I could not find an answer.\"\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "callback = StreamingStdOutCallbackHandler()\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", streaming=True, callbacks=[callback], temperature=0) \n",
    "non_stream_llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "question_generator = LLMChain(llm=non_stream_llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_CHAIN_PROMPT)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=non_stream_llm ,memory_key=\"chat_history\",return_messages=True, output_key=\"answer\")\n",
    "\n",
    "qa = ConversationalRetrievalChain(combine_docs_chain=doc_chain, question_generator=question_generator, retriever=docsearch.as_retriever(search_kwargs={'k':5}), memory=memory, max_tokens_limit=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13d658b0-ac46-4092-99e7-ab2284d00b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryMemory(human_prefix='Human', ai_prefix='AI', llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), prompt=PromptTemplate(input_variables=['summary', 'new_lines'], output_parser=None, partial_variables={}, template='Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:', template_format='f-string', validate_template=True), summary_message_cls=<class 'langchain.schema.messages.SystemMessage'>, chat_memory=ChatMessageHistory(messages=[]), output_key='answer', input_key=None, return_messages=True, buffer='', memory_key='chat_history')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "023dcf4c-29d1-4878-bd33-10e8e8009f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboards in Fiddler are comprehensive views that bring together all of your monitoring data in one place. They include monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards allow you to analyze the overall health and performance of your models and compare multiple models. They provide a detailed view of your model's performance and enable data-driven decision-making to improve AI performance. [^1^]\n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What are dashboards?',\n",
       " 'chat_history': [SystemMessage(content='', additional_kwargs={})],\n",
       " 'answer': \"Dashboards in Fiddler are comprehensive views that bring together all of your monitoring data in one place. They include monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards allow you to analyze the overall health and performance of your models and compare multiple models. They provide a detailed view of your model's performance and enable data-driven decision-making to improve AI performance. [^1^]\\n\\nReference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)\\n\\n\"}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"What are dashboards?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc6b3120-32be-43bb-8ecf-0696ecff32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryMemory(human_prefix='Human', ai_prefix='AI', llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), prompt=PromptTemplate(input_variables=['summary', 'new_lines'], output_parser=None, partial_variables={}, template='Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:', template_format='f-string', validate_template=True), summary_message_cls=<class 'langchain.schema.messages.SystemMessage'>, chat_memory=ChatMessageHistory(messages=[HumanMessage(content='What are dashboards?', additional_kwargs={}, example=False), AIMessage(content=\"Dashboards in Fiddler are comprehensive views that bring together all of your monitoring data in one place. They include monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards allow you to analyze the overall health and performance of your models and compare multiple models. They provide a detailed view of your model's performance and enable data-driven decision-making to improve AI performance. [^1^]\\n\\nReference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)\\n\\n\", additional_kwargs={}, example=False)]), output_key='answer', input_key=None, return_messages=True, buffer='The human asks what dashboards are. The AI explains that dashboards in Fiddler are comprehensive views that bring together all monitoring data in one place. They include monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards allow for analyzing the overall health and performance of models, comparing multiple models, and making data-driven decisions to improve AI performance. [^1^]', memory_key='chat_history')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "653e303b-9d55-4454-b5d2-468433781adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboards in Fiddler are used to create comprehensive views of monitoring data for AI models. They allow users to analyze the overall health and performance of models, compare multiple models, and make data-driven decisions. Dashboards can include monitoring charts for data drift, traffic, data integrity, and performance metrics. They can be customized with flexible filters and chart utilities, such as zooming into data and toggling between line and bar chart types. Dashboards can be saved, deleted, shared, and edited, and they support model-to-model comparison and plotting drift or data integrity for multiple columns in one view.\n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How can i use them?',\n",
       " 'chat_history': [SystemMessage(content='The human asks what dashboards are. The AI explains that dashboards in Fiddler are comprehensive views that bring together all monitoring data in one place. They include monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards allow for analyzing the overall health and performance of models, comparing multiple models, and making data-driven decisions to improve AI performance. [^1^]', additional_kwargs={})],\n",
       " 'answer': 'Dashboards in Fiddler are used to create comprehensive views of monitoring data for AI models. They allow users to analyze the overall health and performance of models, compare multiple models, and make data-driven decisions. Dashboards can include monitoring charts for data drift, traffic, data integrity, and performance metrics. They can be customized with flexible filters and chart utilities, such as zooming into data and toggling between line and bar chart types. Dashboards can be saved, deleted, shared, and edited, and they support model-to-model comparison and plotting drift or data integrity for multiple columns in one view.\\n\\nReference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"How can i use them?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70783fd7-dc2c-42e4-b3e2-6fceba895cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To view the dashboards in the user interface, you can navigate to the dashboard page by clicking on \"Dashboards\" from the top-level navigation bar. This will take you to the Dashboards page where you can select from previously created dashboards or create a new one. You can then access and monitor your models' performance, data drift, data integrity, and traffic on the dashboards.\n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/dashboards-ui](https://docs.fiddler.ai/docs/dashboards-ui)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How can i see it in the UI?',\n",
       " 'chat_history': [SystemMessage(content='The human asks what dashboards are. The AI explains that dashboards in Fiddler are comprehensive views that bring together all monitoring data in one place, including monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards allow for analyzing the overall health and performance of models, comparing multiple models, and making data-driven decisions to improve AI performance. Dashboards in Fiddler can be customized with flexible filters and chart utilities, saved, deleted, shared, and edited. They support model-to-model comparison and plotting drift or data integrity for multiple columns in one view.', additional_kwargs={})],\n",
       " 'answer': 'To view the dashboards in the user interface, you can navigate to the dashboard page by clicking on \"Dashboards\" from the top-level navigation bar. This will take you to the Dashboards page where you can select from previously created dashboards or create a new one. You can then access and monitor your models\\' performance, data drift, data integrity, and traffic on the dashboards.\\n\\nReference URL: [https://docs.fiddler.ai/docs/dashboards-ui](https://docs.fiddler.ai/docs/dashboards-ui)'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"How can i see it in the UI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7f7f986-360f-4dbe-93f2-fb12b7b0b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "class StreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self, container, initial_text=\"\"):\n",
    "        self.container = container\n",
    "        self.text = initial_text\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        self.text += token\n",
    "        self.container.markdown(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d82c623c-8c17-4f8d-8b95-47f2c6b5b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "template = \"\"\"You are a tool called Fiddler Chatbot \n",
    "and your purpose is to use the below documentation from the company Fiddler to answer the subsequent documentation questions.\n",
    "Also, if possible, give me the reference URLs according to the following instructions. \n",
    "The way to create the URLs is: add \"https://docs.fiddler.ai/docs/\" before the \"slug\" value of the document. \n",
    "For any URL references that start with \"doc:\" or \"ref:\" use its value to create a URL by adding \"https://docs.fiddler.ai/docs/\" before that value.\n",
    "Do not use page titles to create urls. Note that if a user asks about uploading events, it means the same as publishing events. \n",
    "If the answer cannot be found in the documentation, write \"I could not find an answer.\"\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "callback = StreamingStdOutCallbackHandler()\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", streaming=True, callbacks=[callback], temperature=0) \n",
    "non_stream_llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "question_generator = LLMChain(llm=non_stream_llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_CHAIN_PROMPT)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=non_stream_llm ,memory_key=\"chat_history\",return_messages=True, output_key=\"answer\", max_tokens_limit=50)\n",
    "\n",
    "qa = ConversationalRetrievalChain(combine_docs_chain=doc_chain, question_generator=question_generator, retriever=docsearch.as_retriever(search_kwargs={'k':5}), memory=memory, max_tokens_limit=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba520198-6c51-4d03-b793-5e159a99db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboards in Fiddler are comprehensive views that bring together all of your monitoring data in one place. They allow you to create monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards provide a detailed view of your model's performance and can be used to inform your team, management, or stakeholders in making data-driven decisions to improve AI performance. You can find more information about dashboards in the [Dashboards Platform documentation](https://docs.fiddler.ai/docs/dashboards-platform)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What are dashboards',\n",
       " 'chat_history': [HumanMessage(content='What are dashboards', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"Dashboards in Fiddler are comprehensive views that bring together all of your monitoring data in one place. They allow you to create monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards provide a detailed view of your model's performance and can be used to inform your team, management, or stakeholders in making data-driven decisions to improve AI performance. You can find more information about dashboards in the [Dashboards Platform documentation](https://docs.fiddler.ai/docs/dashboards-platform).\", additional_kwargs={}, example=False)],\n",
       " 'answer': \"Dashboards in Fiddler are comprehensive views that bring together all of your monitoring data in one place. They allow you to create monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards provide a detailed view of your model's performance and can be used to inform your team, management, or stakeholders in making data-driven decisions to improve AI performance. You can find more information about dashboards in the [Dashboards Platform documentation](https://docs.fiddler.ai/docs/dashboards-platform).\"}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"What are dashboards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfb3213f-259b-48cf-83b0-3833d09a93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboards help with performance metrics by allowing you to create comprehensive views of your model's performance. You can add monitoring charts for performance metrics to your dashboards, which provide visualizations and insights into how well your model is performing. Dashboards enable you to track changes over time, identify patterns, and make data-driven decisions to improve your AI performance. \n",
      "\n",
      "Reference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How are they helpful for performance metrics?',\n",
       " 'chat_history': [HumanMessage(content='What are dashboards', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"Dashboards in Fiddler are comprehensive views that bring together all of your monitoring data in one place. They allow you to create monitoring charts for data drift, traffic, data integrity, and performance metrics. Dashboards provide a detailed view of your model's performance and can be used to inform your team, management, or stakeholders in making data-driven decisions to improve AI performance. You can find more information about dashboards in the [Dashboards Platform documentation](https://docs.fiddler.ai/docs/dashboards-platform).\", additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='How are they helpful for performance metrics?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"Dashboards help with performance metrics by allowing you to create comprehensive views of your model's performance. You can add monitoring charts for performance metrics to your dashboards, which provide visualizations and insights into how well your model is performing. Dashboards enable you to track changes over time, identify patterns, and make data-driven decisions to improve your AI performance. \\n\\nReference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)\", additional_kwargs={}, example=False)],\n",
       " 'answer': \"Dashboards help with performance metrics by allowing you to create comprehensive views of your model's performance. You can add monitoring charts for performance metrics to your dashboards, which provide visualizations and insights into how well your model is performing. Dashboards enable you to track changes over time, identify patterns, and make data-driven decisions to improve your AI performance. \\n\\nReference URL: [https://docs.fiddler.ai/docs/dashboards-platform](https://docs.fiddler.ai/docs/dashboards-platform)\"}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"How are they helpful for performance metrics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62626d29-5039-445a-ae84-aebb4d685247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
