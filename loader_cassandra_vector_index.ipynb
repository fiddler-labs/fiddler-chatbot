{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3d3af9-e777-4e44-adff-da030fecfb4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4692e2-db8d-49d4-939b-c169ea805eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q cassandra-driver\n",
    "!pip install -q cassio\n",
    "!pip install -q langchain\n",
    "!pip install -q typing-inspect==0.8.0 typing_extensions==4.5.0\n",
    "!pip install -q pydantic==1.10.11\n",
    "!pip install -q flask-sqlalchemy\n",
    "!pip install -q unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd0fbb-d55c-46bc-86da-dc4c2cbfdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q fiddler-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e378b1f5-7d4a-4002-b16e-1515b12bda1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-cpu==2.12.0 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-cpu==2.12.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q --progress-bar off \\\n",
    "    \"git+https://github.com/hemidactylus/langchain@updated-full-preview--lab#egg=langchain&subdirectory=libs/langchain\" \\\n",
    "    \"cassio>=0.1.1\" \\\n",
    "    \"google-cloud-aiplatform>=1.25.0\" \\\n",
    "    \"jupyter>=1.0.0\" \\\n",
    "    \"openai==0.27.7\" \\\n",
    "    \"python-dotenv==1.0.0\" \\\n",
    "    \"tensorflow-cpu==2.12.0\" \\\n",
    "    \"tiktoken==0.4.0\" \\\n",
    "    \"transformers>=4.29.2\" \n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4096ec-29eb-4cfa-8346-7b283cbd23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassandra\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import fiddler as fdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c65fe4-ee0c-4262-969a-d4e6f97ebc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0.dev1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c37535-3311-495a-921e-4d175f6eaf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.29.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d4a0d-10d5-4491-aa06-019378450ebe",
   "metadata": {},
   "source": [
    "### Connect to DataStax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b3d41-2153-45c4-b37b-8567ca48c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This secure connect bundle is autogenerated when you donwload your SCB, \n",
    "# if yours is different update the file name below\n",
    "cloud_config= {'secure_connect_bundle': 'datastax_auth/secure-connect-fiddlerai.zip'}\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = 'ADD Your Token'\n",
    "#print(\"TOKEN: \" + ASTRA_DB_APPLICATION_TOKEN)\n",
    "\n",
    "auth_provider=PlainTextAuthProvider(\"token\", ASTRA_DB_APPLICATION_TOKEN)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5beb68-14d7-4b67-bd02-44d4dea4d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('fiddlerai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5590ec5f-b046-4fba-8849-6bb97df81472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your secret(s) for LLM access:\n",
    "llmProvider = 'OpenAI'  # 'GCP_VertexAI', 'Azure_OpenAI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58474de6-daee-4d67-b5f5-d3099d9519be",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']='ADD Your OpenAI Key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9041101-86be-41ec-9b20-db246fbbce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader, DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "706025b0-e3b9-4f95-8f03-40591d854858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef53f093-39d2-4a08-84bd-a6aa1b6440c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97ed5b8a-e8e0-48cf-aa49-eed9ec6c1bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM+embeddings from OpenAI\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_TYPE'] = 'open_ai'\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "llm = OpenAI(temperature=0)\n",
    "myEmbedding = OpenAIEmbeddings()\n",
    "print('LLM+embeddings from OpenAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f323bb1d-8bc6-4cd9-a39c-372cfd8c7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'fiddler_doc_snippets_' + llmProvider\n",
    "\n",
    "index_creator = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=Cassandra,\n",
    "    embedding=myEmbedding,\n",
    "    text_splitter=CharacterTextSplitter(\n",
    "        chunk_size=5000,\n",
    "        chunk_overlap=0,\n",
    "    ),\n",
    "    vectorstore_kwargs={\n",
    "        'session': session,\n",
    "        'keyspace': 'fiddlerai',\n",
    "        'table_name': table_name,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f1bc517-6674-4c23-a3d9-c43df13e1f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---\\ntitle: \"fdl.FiddlerApi\"\\nslug: \"client-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slug: \"client-setup\"     url=URL,\\n    org_id=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---\\ntitle: \"Customer Churn Prediction\"\\nslug:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slug: \"customer-churn-prediction\"  \"https://fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slug: \"customer-churn-prediction\" ca-1.png\",\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>Currently, only the following fields in [fdl.M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>AI has been in the limelight thanks to â€Œrecent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>LLM means large language model.  A large langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>The term generative AI, or GenAI, also is clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>FM, or FMs, means Foundation Models.  Foundati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4158 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     ---\\ntitle: \"fdl.FiddlerApi\"\\nslug: \"client-se...\n",
       "1     slug: \"client-setup\"     url=URL,\\n    org_id=...\n",
       "2     ---\\ntitle: \"Customer Churn Prediction\"\\nslug:...\n",
       "3     slug: \"customer-churn-prediction\"  \"https://fi...\n",
       "4     slug: \"customer-churn-prediction\" ca-1.png\",\\n...\n",
       "...                                                 ...\n",
       "4153  Currently, only the following fields in [fdl.M...\n",
       "4154  AI has been in the limelight thanks to â€Œrecent...\n",
       "4155  LLM means large language model.  A large langu...\n",
       "4156  The term generative AI, or GenAI, also is clos...\n",
       "4157  FM, or FMs, means Foundation Models.  Foundati...\n",
       "\n",
       "[4158 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('documentation_data/vector_index_feed_24.1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76211ae4-6cc1-4b5e-aa92-cca6c7338330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4158"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataFrameLoader(df, page_content_column=\"text\")\n",
    "len(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4453446d-71b6-4da5-915e-f62d5177af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 612185, Requested 757379. Please try again in 22.173s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 522028, Requested 757379. Please try again in 16.764s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 432052, Requested 757379. Please try again in 11.365s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 340597, Requested 757379. Please try again in 5.878s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 810449, Requested 762194. Please try again in 34.358s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 720569, Requested 762194. Please try again in 28.965s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 629335, Requested 762194. Please try again in 23.491s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 540614, Requested 762194. Please try again in 18.168s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 383843, Requested 762194. Please try again in 8.762s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 820186, Requested 646745. Please try again in 28.015s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 730444, Requested 646745. Please try again in 22.631s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 641779, Requested 646745. Please try again in 17.311s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 553182, Requested 646745. Please try again in 11.995s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-VifEdlDlDNEVzwTxlrODi3pU on tokens per min (TPM): Limit 1000000, Used 398647, Requested 646745. Please try again in 2.723s. Visit https://platform.openai.com/account/rate-limits to learn more..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.cassandra.Cassandra object at 0x12cee8ac0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = index_creator.from_loaders([loader])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0a75294-e010-4999-9385-8924d975db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 0:\n",
      "    row_id:            c37e08bf1c8c4756b3780e7d3c000073\n",
      "    vector:            [-0.015756040811538696, 0.014646461233496666, 0.0119418594986200 ...\n",
      "    body_blob:         BlogLink:https://www.fiddler.ai/blog/monitoring-natural-language-processing-and-computer-vision-models-part-3 Content: In the previous parts of this blog series about monitoring models with unstructured data, we covered Fiddlerâ€™s approach to monitoring high-dimensional vectors, and how this method can be applied to computer vision use cases.Â  In part 3, we will discuss why monitoring natural language processing (NLP) models is important, and show how Fiddler empowers data scientists and ML practitioners with NLP model monitoring. We will present a multi-class classification example which is built using the 20 Newsgroups dataset and use text embedding generated by OpenAI.Â  Over the past decade, NLP has become an important technology adopted by data-driven enterprises. Investments will continue to pour into NLP solutions to maximize business value from conversational and Generative AI. In general, NLP refers to a group of tools and techniques that enable ML models to process and use human language â€” as text or audio format â€” in their workflow. Some examples of NLP use cases include, but are not limited to, text classification, sentiment analysis, topic modeling, and named entity recognition. A wide set of tools and techniques are available today for building NLP models, from basic vectorization and word embeddings (e.g., tfâ€“idf and word2vec) to sophisticated pretrained language models (BERT, GPT-3) to custom-made transformers. NLP models are vulnerable to performance degradations caused by different types of data quality issues after deployment. Similar to other types of machine learning models, the general assumption for model performance evaluations is that the underlying data distribution remains unchanged between training and production use. This assumption, however, may not always be valid in the real world. For example, a new meme or political topic, fake product reviews generated by bots, or natural disasters and public health emergencies, like the COVID-19 pandemic, are all scenarios in which NLP models may encounter a shift in the data distribution (also known as data drift). Given the prevalence of NLP data across different industries, from healthcare and ecommerce to fintech, it is important to minimize the risk of model failure and performance degradations by monitoring NLP models. Therefore, NLP model monitoring is becoming an essential capability of any monitoring framework. In response to this need, we have previously launched NLP model monitoring capabilities to the Fiddler AIÂ Observability platform, which enables our customers to gain better visibility of their NLP pipelines, detect any performance and drift issues, and take timely actions to minimize risks that negatively impact their business. Modern NLP pipelines process text inputs in steps. Text is typically converted to tokens, and an embedding layer maps tokens into a continuous space â€” the first of many vector representations. There are sometimes several representations which can be used for monitoring; we've found that some act as early warnings while those further downstream track actual performance degradation more closely. Fiddlerâ€™s approach to monitoring NLP models is based on directly monitoring the vector space ofÂ  text embeddings. If desired, Fiddler can monitor multiple vector representations simultaneously for the same text input. In some cases, using simple pre-trained word-level embeddings, like word2vec, or even term frequency (TF-IDF) can provide sufficient sensitivity to semantic shift. Users can set custom model monitoring alerts to get early warnings on changes in the distribution of vectors which can potentially affect the expected behavior of the model. Examples of such changes include a significant distributional change in the high-dimensional vector embeddings of text data, occurrence of outliers, or out-of-distribution data points at production time. Fiddler has developed a novel clustering-based approach ...\n",
      "    metadata_s:        None\n",
      "\n",
      "Row 1:\n",
      "    row_id:            5b1aa5603bca4f42b3b915a51bf388b5\n",
      "    vector:            [-0.002448877552524209, 0.03361177816987038, 0.01357241999357938 ...\n",
      "    body_blob:         slug: \"simple-nlp-monitoring-quick-start\" Klc7HoZ2/rk9fUC778XHj9Qz4rO8lqH7gAy4CiCxUFiMIFWmbJrL4dWOvg6YPUztPQMjQInIB6LoRxBBdlTUigqlGAUT14X9X4Z8zSOgI2VVp6g4PHsDEX1DKqGCIDyC2AaJY1bjq2OG1pSFD77QxGuy2rJvvOTI+HBJYQ10OfSNDgbxTbEh8Y7kMCRGRbVos8AziGP1NCWVMQOlrgZIsgsNxTHQKhi2sHHYfcSp99kEkguc7dsr9AVRGEjGmy9+Cy0JHKK/HsCq5gP1wpsB4xRHOZ/lk3/jITyejSFK3lPTNs4xKvf3SeVY52Ff3Zm0rAMzcxa9c/bdUYrAoY1n2n7qEmhAAVkVpEAcNcOY/GCr17hQaeI8R0XsKaeX97H6Ry/bBKHWQWCvKBfOhc2Xc1ljmIsPM97Df2VunfjkHt+dsr2LfECYLa49oCq0KJtJ6YCBEomq3FEW9LwvWuTh+kdOk+xnnUPglom6oVLhOCUhKc5odOoRVlhz6Xj1HABCAEEefFGBMVWPGgFCsprDqBCFFSBaoqZnztpgNq/r8vec9Y5rrks4NsmQmWcf9Mv/DMQJ7pLYM+BiJu6GSLe+fkA71zn1960t1YyaLI4wrkUTDzbgFo3cagQaeK+nhAUWolUXUu7CrDpEyqqrX3p1t79xSqbBlv39dtNdArzfcKMKyGNDN45oY+eUOi/u3y5gmqUMXRoj9d6Qpw5vzzKCxZruDnHCIhujRo7TyIDM+cqDEg0nOrkwCBUiJlhBmXtxhbqvEFGz4cKsb3LX+60EWRyAepnSPivm1zCBIg8ZcYydgwUfJHHg103B0R9cFfFpHUKv8S9EY9KboXZlXyk6Z6FfgQ0GSaN3zBtLcTPOpTpMzWjHwMLzP0+VN6X0ao/Zzzz0V19xbi6BCuAIWgokMF1ohBx48HwhnpwU6MOdveQpNzOtChdx/THYkzvQfzPzf97T10KZZW24J6H3zQIrOL3NxYCjOqafK+tq+dgDOQjWe3gyhKp+ti+qjVIKEdkQ8BoC5YPlEK+0V ...\n",
      "    metadata_s:        None\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "cqlSelect = f'SELECT * FROM fiddlerai.{table_name} LIMIT 2;'  # (Not a production-optimized query ...)\n",
    "rows = session.execute(cqlSelect)\n",
    "for row_i, row in enumerate(rows):\n",
    "    print(f'\\nRow {row_i}:')\n",
    "    # depending on the cassIO version, the underlying Cassandra table can have different structure ...\n",
    "    try:\n",
    "        # you are using the new cassIO 0.1.0+ : congratulations :)\n",
    "        print(f'    row_id:            {row.row_id}')\n",
    "        print(f'    vector:            {str(row.vector)[:64]} ...')\n",
    "        print(f'    body_blob:         {row.body_blob} ...')\n",
    "        print(f'    metadata_s:        {row.metadata_s}')        \n",
    "    except AttributeError:\n",
    "        # Please upgrade your cassIO to the latest version ...\n",
    "        print(f'    document_id:      {row.document_id}')\n",
    "        print(f'    embedding_vector: {str(row.embedding_vector)[:64]} ...')\n",
    "        print(f'    document:         {row.document[:64]} ...')\n",
    "        print(f'    metadata_blob:    {row.metadata_blob}')\n",
    "\n",
    "print('\\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9e701-49fa-49cd-9e30-3ab1bd2cd636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"What is Fiddler?\"\n",
    "index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd67ae-2260-4566-a23e-f981f69cc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "createTableSQL = \"\"\"CREATE TABLE fiddler_chatbot_history (\n",
    "    row_id text PRIMARY KEY,\n",
    "    response text,\n",
    "    response_vector vector<float, 1536>,\n",
    "    source_docs text,\n",
    "    source_docs_vector vector<float, 1536>,\n",
    "    question text,\n",
    "    question_vector vector<float, 1536>,\n",
    "    comment text,\n",
    "    feedback int,\n",
    "    metadata_s map<text, text>,\n",
    "    ts timestamp)\"\"\"\n",
    "# ) WITH additional_write_policy = '99p'\n",
    "#     AND bloom_filter_fp_chance = 0.01\n",
    "#     AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
    "#     AND comment = ''\n",
    "#     AND compaction = {'class': 'org.apache.cassandra.db.compaction.UnifiedCompactionStrategy'}\n",
    "#     AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
    "#     AND crc_check_chance = 1.0\n",
    "#     AND default_time_to_live = 0\n",
    "#     AND gc_grace_seconds = 864000\n",
    "#     AND max_index_interval = 2048\n",
    "#     AND memtable_flush_period_in_ms = 0\n",
    "#     AND min_index_interval = 128\n",
    "#     AND read_repair = 'BLOCKING'\n",
    "#     AND speculative_retry = '99p';\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a1bad-c048-40a9-b9b6-c070a28a4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(createTableSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2668f-2d7a-454a-9024-8aefbe645ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "response = openai.Embedding.create(model=EMBEDDING_MODEL, input='How are you doing')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b3082-7539-4b3d-8beb-1f171345d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_factory(colnames, rows):\n",
    "    return pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "session.row_factory = pandas_factory\n",
    "session.default_fetch_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4758a9-fa0e-494a-bda5-0868b2d0ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = session.execute('SELECT * from squad')\n",
    "    \n",
    "df_baseline = rows._current_rows\n",
    "df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c4d5b-1cf4-49da-b9cd-b7d53eb8e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = df_baseline.dtypes\n",
    "\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517937fc-1fe1-49cd-b7c5-a3040d2dc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline['answers'] = df_baseline['answers'].apply(lambda x : str(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
